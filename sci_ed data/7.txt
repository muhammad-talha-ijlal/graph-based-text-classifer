 A Primer for the 21st Century: The 5 Systemic Changes This article presents my thinking and writing over the last three years. I present some fundamental concepts in science, innovation and technology in order to better explain the Fourth Industrial Revolution (4IR) and the social, political and economic consequences. The anticipated scale of the changes is unequaled in human history. A recurring theme is the environmental problems that will plague this century. My objective is not to predict the future but rather to help the reader appreciate the opportunities of the 4IR and plan and prepare for them. I use a planning horizon of one hundred years, which is what I foresee human life expectancy will be. Introduction “We live in a time where all current systems of human thought from physics to politics are dominated by a set of underlying assumptions that are mostly outdated and no longer work in a very different world that is more interdependent and connected than ever before in human history.”[1] — Fritjof Capra Civilization is going through a period of change comparable to the Renaissance. Every facet of society will be transformed by new fundamental science, technology and ways of thinking, partly as a means to address problems of incomparable scale. We face an unavoidable environmental deadline, exponential growth in new information brought about by a new technology paradigm, a dramatic increase in awareness of social and economic inequities and an unprecedented level of Black Swan events. All of this is further complicated by technologies that support a large group of “bad actors” inside and outside the system who put self-interest ahead of the principles that protect natural and man-made systems. As daunting as this scenario may appear, I think the situation is much worse. Capra makes the point well — the underlying assumptions of all our thinking are outdated. In 2016 the World Economic Forum declared the current period in history the ‘Fourth Industrial Revolution (4IR), another period in which technology will transform the manner and standard of living. I think the expression “4IR” understates the current situation. The magnitude of change will be like no other period in human history. We are currently on the verge of five simultaneous systemic transformations, which together will have a scale and magnitude of impact that is comparable to a Renaissance. The five systemic transformations are: 1. Science 2. Economic System 3. Political System 4. Environment 5. Education Since the 17th-century science has advanced rapidly to positively impact the economic and social system. With engineering, this science has been given purpose and converted into technology. With positive effects from economies of scale, network effects and globalization, the new technology created rapid economic expansion and positive social benefit. In the 20th Century quantum mechanics, complexity science and information theory were discovered. In the 21st century these three bodies of scientific thought will transform not only our modern lives but also our understanding of reality in an epistemological sense. Sometime between 1995–2010 the historic wealth creation model changed from a model driven by tangible inputs — land and labor — to intangible inputs — information and computation.[2] This change in the wealth creation model is the transformative change in the economic system in the 21st century. In order to understand this change, we need to understand the first new technology paradigm of the 21st century and the 4IR — Artificial Intelligence (AI), Cloud Computing and Internet of Things (IOT). The change in the political system is probably my most speculative conclusion. Network science explains the current growth in the Internet and cities. These trends may be supported by non-hierarchical Blockchain technology to support a rebirth of local communities. If local communities really take hold, I predict a weakening of the political system at the federal and state government level in favor of stronger cities and self-organizing communities. The recent rollback in Internet businesses and bitcoin mining in China may be evidence to support my thinking. The Chinese government is showing fear of threats to their centralized power. The trend toward problem resolution in real-time, digitally, also supports a stronger government closer to the citizens at the city level. Understanding the environment dates back to the 18th century when the renowned naturalist Alexander von Humboldt noticed the negative impact of an erupted volcano on local plant life in Ecuador. The Krakatoa eruption in Indonesia in 1883 gave us another dramatic lesson when a cloud of volcanic ash covered the earth for three years. Finally, in 1965 man began a timid response to environmental problems with the formation of the Club of Rome. MIT professor Jay Forrester’s “systems analysis” for Club of Rome predicted the environmental apocalypse around 2050 that is now approaching. Halting the environmental degradation of hundreds of years will require a complete reconsideration of water, food, oceans, cities, energy and even matter itself (regenerative). This reconsideration and a systemic transformation may be a life or death challenge. The education system was formalized in the early 19th century to train workers for the emerging industrialization in countries such as the U.S. The system used rote memorization to teach reading, writing and arithmetic and in the case of the U.S to transfer a democratic value system to recently arrived immigrants. This logic was never really updated, although experiments such as Montessori schools achieved some scale. STEM education (Science, Technology, Engineering and Math) finally became a popular mantra in 2001 when introduced by the NSF (National Science Foundation). However, the educators did not update for the latest science and computing. Instead, the U.S. focused on standardized tests to mostly teach 19th-century knowledge and missed the chance to modernize educational curriculum and pedagogy. The purpose of this article is to understand the five systemic transformations which are today coincident. Each of these five systems is part of a phase change in the current social structure. A phase change in physics is when a system transitions from one state of matter to another (water to ice) and for a period of time there is chaos. According to Eric Beinhocker, Executive Director of the Institute for New Economic Thinking at Oxford, a phase change in modern society manifests in a combined period of social, economic and political chaos. Sound familiar? “Trump, BLM, China, COVID-19, Global Warming, Misinformation”. The phase change continues until the information infrastructure is prepared to handle the next level of economic advancement, a new technology paradigm is in place, and the chaos then subsides and economic growth should accelerate. Historically, when we have gone through a phase change, such as with the introduction of electricity and the “Roaring 20s”, we have had changes in science, technology and the economic system, but the political changes were minimal and the environment was, of course, ignored completely. The public education system was rarely ever mentioned. This scale and magnitude of the coming change naturally suggests to me that we must think differently in the 21st century, as Capra points out in the quote to begin the article. In order to think differently, we need new assumptions (the earth is flat) and new insights (maybe the earth is round). Assumptions are fundamental premises critical to the logic of the derived conclusion. Insights are novel intuitions, the original product of the discovery process that leads to new hypotheses for ideas or theory. When I speak about thinking differently, I want the reader to understand the new assumptions necessary to develop their own insights about the future. This self-directed learning is the model for the 21st century and another important theme in this article. Constant self-directed learning is the foundation of the new approach to education and learning that is required for success in the 21st century. The noted management theorist Peter Drucker wrote in 1997[3]: “In human affairs — political, social, economic, or business — it is pointless to try to predict the future, let alone attempt to look ahead 75 years. But it is possible — and fruitful — to identify major events that have already happened, irrevocably, and that will have predictable effects in the next decade or two. It is possible, in other words, to identify and prepare for the future that has already happened.” The purpose of this article is not to predict the future so much as to give the reader a set of assumptions that should guide their thinking and behavior in the 21st century. If you have followed the writings of Charlie Munger, Ray Dalio or Shane Parish at Farnam Street, you have noticed the popularity of mental models, formal frameworks for how to think better about problems. Frameworks are great and I teach them every chance I get. However, the results are only as good as the assumptions underpinning the thinking. My goal in this book is to stimulate the reader’s thinking about some new assumptions for how to consider the 21st century. No seatbelts are provided. Section I-The Three Sciences Shaping the 21st Century: “As the mathematician John Allen Paulos so eloquently said, “Uncertainty is the only certainty there is, and knowing how to live with insecurity is the only security.” This is, I think, life’s most important lesson.”[4] –Melanie Mitchell “Knowledge consists in the search for truth … It is not the search for certainty.”[5] — Karl Popper In this section I am going to take on the daunting task to explain in more detail the three key scientific bodies of thought that are shaping the 21st century. I am not going to exhaustively detail every important concept in each of the three fields of science. Rather, I am going to provide the extract from each that will serve as the foundation to change all of your assumptions about reality. In other words, I am going to take your public school education built on 19th-century thinking and “facts” and throw it in the wastebasket. In the writing that follows I will hopefully present the foundation for some new assumptions. The three sciences shaping the 21st century are: 1. Quantum Mechanics 2. Complexity Science 3. Information Theory All three of these sciences are now mature enough that they serve as the basis for engineered technology impacting millions of people. Information Theory is clearly the most advanced in its use in engineering as the basis for the Digital Age. Complexity Science has the furthest to go to significantly become engineered, but a good first step was the 2021 Nobel Prize in Physics to Syukoro Manabe, Klauss Hasselmann and Giorgio Parisi “for groundbreaking contributions to our understanding of complex systems”. Quantum Mechanics may very well have the greatest impact if quantum computing (QC) is successfully commercialized. Quantum Mechanics “We are pressured to reimagine the fundamental nature of reality as an uncertain fog of possibilities, of particles that are there and not there.”[6] — Janna Levin Quantum Mechanics (QM) is a theory in physics that provides a microscopic view of reality, wherein sub-atomic particles combine to fashion atoms, molecules and eventually all matter. This theory superseded much of Newtonian physics and its inherently macroscopic approach. All of us tend to think in terms of Aristotelian logic — A or ~A (pronounced A or not A). QM proposes that particles may have many states, a probabilistic view called qubits, where the actual state is only determined at the time of measurement. In other words, reality is based on the uncertainty of sub-atomic particles. Such a fact is perhaps not so surprising when we realize that all of human cognition is devoted to managing uncertainty. With every new piece of information, a human processes the same question. Does this new perception, data or information warrant to be part of my existing mental framework of knowledge? Or, do I reject the input as quickly as possible in order to conserve energy. Adding to the mental framework or rejecting the input is the management of uncertainty. This explanation may help us to see the need to reconsider uncertainty. Uncertainty is as much a part of reality as oxygen or solar energy. This view of uncertainty conflicts with our intuition to “find” the rationality in a deterministic, causal world. These rationalistic, deterministic frameworks are useful to conserve energy and make life less challenging, but they create a bias that makes it more difficult to understand a world becoming more and more complex and uncertain. As the modern network creates the likelihood of unintended consequences, in part through new feedback loops triggered by previously unconnected components, we approach an unpredictable future. Nassim Taleb explains the point well: “In a fragile system, stressors create uncertainty. There is existing purpose in your world, and that purpose makes sense so long as your world remains within a certain state. But when a stressor throws your world into a new state, the established purposes inside your world make less sense. Your world becomes more uncertain. That’s fragility.”[7] Taleb calls the major stressors, the “large-scale unpredictable and irregular events of massive consequence”, Black Swans. When we look at QM in terms of math, we start to see the power of a potential technology. Traditional computers use bits that have one of two states, 0 or 1 (very Aristotelian) and they are standalone states that do not interact. In QC qubits have many states, the probability in the range 0 to 1. Qubits, in contrast to bits, can interact positively and negatively (additively) like two similar forces. If an algorithm can harness the additive power of qubits, the computational power of the computer increases exponentially beyond current analytical approaches. If the technology reaches the level of 64 qubits, the functionality of the computer would be 100X greater than current supercomputers and would permit us to deal with problems that require very large data sets. Problems such as climate simulations, supply chain optimization, drug discovery, financial instrument pricing and cybersecurity are the types of complex, million variable problems suitable for QC. BCG, the international consulting firm, estimates that “QC could create value of $450 billion to $850 billion in the next 15 to 30 years”. Now that the Biden administration has made us comfortable with “trillions” of dollars, this estimate may not look so exciting. Do not forget the QC is being applied to the most difficult natural and manmade problems that might take thousands of years to solve with traditional computer technology. These are the problems where we never had viable computational approaches before. This type of knowledge and understanding derived by QC hopefully will provide long-term holistic solutions to the most complex social and scientific problems. “I can live with doubt and uncertainty and not knowing. I think it is much more interesting to live not knowing than to have answers which might be wrong … In order to make progress, one must leave the door to the unknown ajar.”
 –Richard P Feynman[8] Complexity Science “At the core of areas of study as diverse as cognitive psychology, artificial intelligence, economics, immunogenesis, genetics, and ecology, we encounter nonlinear systems that remain far from equilibrium throughout their history. In each case, the system can function (or continue to exist) only if it makes a continued adaptation to an environment that exhibits perpetual novelty.”[9] — John Holland Credit: https://www.frontiersin.org/articles/10.3389/fnins.2015.00014/full The laws of physics do not seem to improve with the universe’s experience.[10] Chemistry does not do much better. Only in biochemical systems, living systems, do we see evolution and adaption and in manmade systems the adaption is called innovation. It is in this quality of adaption that we see the link between molecules, cells, systems, organisms, species and manmade organizations such as corporations, universities and cities. The science to explain all natural and manmade systems is complexity science and the area of study is [all] complex systems. Complex systems process or transform energy, matter and information as inputs in order to adapt and survive. Recognizing the principles of quantum mechanics, the systems are uncertain or stochastic, non-linear and in a constant state of change that never reaches an equilibrium. Each system has a boundary that defines it. The boundary is a simple X, ~X (X, not X), inside the system or not. Inside the system we have agents and other components. The agents are capable of adapting, learning and responding to the environment inside and outside the boundary. The components are information, matter and energy. Through evolution complex systems have acquired the characteristics that allow them to explain both simple single-cell organisms and the most sophisticated systems such as financial markets and cities. This flexibility is made possible because the agents in the system are networked. This networking aids resilience, robustness and inter-dependency[11]and operates whether we think of the network as physical or social. This concept of network is a key concept in understanding how complex systems span from natural to manmade systems. This network functionality also gives the systems the ability to self-organize without relying on a leader. This structure and the functionality can use the self-organizing feature to produce functionality and phenomena at one scale that were not present at a lower scale. This behavior we call emergence. The transition from water to gas is a simple example of emergence. A phase change precedes emergence. A phase change occurs when “micro-components get rapidly reconfigured into a qualitatively different macro-structure”, explained in part by the fact that all systems achieve outcomes that can only be attributed to “all of the parts interacting, not any one of the parts in isolation”.[12] Many explain emergence simply as “the whole is greater than the sum of the parts”. When we think about reality in terms of simply components, and the combining of components as the method to create new outcomes, we realize that the natural world must rely on emergence for its inventiveness (and evolution for the continuity). Emergence has allowed us to start to develop theories to explain life, consciousness and creativity, all of which phenomena appear to me to be emergent. Emergence also allows us to understand the hierarchical, bottom up nature of complex systems. Sub-systems, self-directed, can combine with other systems to increase functionality and survivability beyond what the component systems provide. For example, the human digestive system includes seven organs, each of which individually meets the requirements to be classified as a system, but the full functionality only emerges in the totality of the digestive system. Complexity in the scientific sense is not easy to understand and is not yet widely accepted. In fact, it questions much of science before the 20th century. The diagram below may help a bit or further confuse you, but the article (Bale, Varga, Foxon 2015) from which it is derived is an excellent overview of complexity and related modeling.[13]  The power of complexity to explain both natural and manmade systems is grounded in the concept that man as actor is still guided by our evolutionary preparation or in simpler terms biomimicry. For example, think about the popular concept of “agile” modern management — small independent (self-directed) teams (of systems, agents), self-organized to responsibly respond to real-time information (input) [in real time]. This management concept is almost the definition of a complex system, made possible by our advanced state of digital networking which finally reaches performance standards in real-time similar to every animal looking to survive. The challenge in modern management is to learn how to build up the hierarchy of teams into larger scale systems (digestive system). This larger system ideally creates emergence and more economic value than the simple contribution of each agent. I have been studying complexity since 2010, beginning with the writings of Cesar Hidalgo then at MIT and later at Harvard. For the first three years I was afraid to teach complexity at FIU or MIT. I found it to be profoundly in conflict with my training in Aristotelian epistemology and logic. The writings of the researchers at Santa Fe Institute, the leading research center studying complexity, helped me to get over my philosophical anxiety. I now believe that the solution to any management, organizational or strategic problem should be evaluated for compliance with the principles of complexity science. If complexity explains all natural and manmade systems, then any socio-cultural, political or management decision should be consistent with the principles of complexity science. Information Theory “… the methods of information theory derive from statistical mechanics, which is probabilistic and, at its base, quantum-mechanical. Information theory originated a century ago when Maxwell, Boltzmann, and Gibbs developed successful statistical treatments of thermodynamics problems. Fifty years later, their work formed the mathematical basis for Shannon’s development of a formal theory of information for the purposes of communication, a theory that has expanded to encompass a variety of subjects in computation, control, artificial intelligence, robotics, and a host of other fields.”[14] — David Krakauer, Hidden in Plain Sight We can argue about which scientific theories have most changed life as we know it, but Claude Shannon’s work in information theory should be on everyone’s list. In1948 he wrote a paper, ‘A Mathematical Theory of Communication’ while working as a researcher at Bell Labs. This paper had two profound results: 1. It provided the mathematics to explain how any wave could be digitized and this digital information transmitted over various channels, processed and stored.[Information Theory] 2. It expanded the physicist’s view of reality beyond matter and energy to include information. “The study of the maximum number of states that can be transmitted from one point to another across a channel, in the face of noise and when efficiently encoded is called information theory.”[15] States are equivalent to what we now commonly call “bits” and maximization advanced the technology to improve speed of transmission in a channel and compression of data. This focus on maximization also led to the distinction between signal and noise in a transmission. Simply put, signal is information with purpose and noise is variability in signal quality. The examination of signal and noise led to the realization that information theory is a form of the second law of thermodynamics — entropy. Information is minimized when predictability is maximized or information is maximized when uncertainty is the highest. This point can be demonstrated simply. A flipped coin that comes up heads or tails provides no information to reduce uncertainty. A flipped coin that lands on the edge is a totally unpredictable result that carries with it much information. This coin carries some special information, which brings us to the second contribution from information theory — a redefinition of reality. To better understand, let’s return to the concept of “emergence” in complexity theory. “In a general sense, emergence can be defined as information that is not present at one scale but is present at another scale. This perspective avoids problems of studying emergence from a materialistic framework…we can understand emergence as information that is not present at one scale but is present at another scale. For example, life is not present at the molecular scale, but it is at the cell and organism scales.”[16] The example of the molecule and cell and resultant life at a higher level shows that something exists beyond matter and energy that is necessary for life to emerge and we call that information — the third input to understand reality. If you are fascinated by this explanation of life, this podcast[17] by Sara Imari Walker provides much more understanding on the origins of life and the role information theory may play. If you prefer an earlier perspective on the same issue, Erwin Schrodinger’s book (1944), What is Life, lays down much of the groundwork. If this example about life does not help you to understand the role of information, perhaps pure physics will prove useful. “Modern physics now considers the bit (binary digit) — the binary choice — as the ultimate fundamental entity. John Wheeler (1988), expressed this idea as “it-from-bit”, and implied that the basis of the physical universe — the “it” of an atom or subatomic particle — is not matter, nor energy, but a bit of information. Consequently, the entire universe should be seen as a cosmic processor of information. If elementary particles interact, they are exchanging bits or, in other words, they transmit quantum states. “The [U]niverse can thereby also compute its own destiny… The expanding Universe can, in this view, be considered as the outcome of an entropic force which in its turn gives rise to the accumulation of information that provided biological evolution with a life conferring potential.”[18] A “fundamental entity” in physics would explain reality and be logically consistent with the components of matter and energy. The power of information theory is shown by its influence in science, engineering and mathematics. Rarely does a body of thought influence all three fields. Information theory has influenced telecommunications capacity across a wide range of methods (channels), such as telephony, digital, satellite and broadcast. Network structure explained in statistical terms is perhaps the area where information theory has had the most effect, influencing the understanding of adaption in systems, origins of life and even economics. In 2001 George A. Akerlof, A. Michael Spence and Joseph E. Stiglitz won the Nobel Prize in Economics for their work on asymmetry of information (information theory). The third application area of information theory is in coding theory, cryptography and cybersecurity. To explain network structures that are present in every natural and manmade system in terms of statistical relationships suggests to me that we have only started to explore the applications of information theory to the most challenging problems. David Krakauer makes the point well: ‘The other radical consequence of seeing life as a dance of information that rides matter is that this emergence continues upwards in scale. Just as new rules appear for cells, so too do they appear for collections of cells in animals or plants. And then even newer rules appear higher up on the level of ecosystems made of many animals and plants. At even higher levels still, new laws and structures must emerge in the creation of social organizations via ants, tribes of chimps, and even global technological cultures.”[19] Summary: The purpose of this chapter has been to describe the three fields of science and related technology that are shaping the 21st century. Perhaps a summary will help: 1. QC is a technology that could allow man to understand for the first time problems that may require the integration and analysis of exabytes of data. This technology could open up the entire class of social science problems to computational methods. 2. Complexity science provides an analytical and modeling approach to understand natural and manmade systems (and problems), which may serve mankind well as we tackle the environmental crisis. 3. The network structures that are present in every natural and manmade system can be explained in terms of statistical relationships, which allows us to better understand the role of information theory in an ever increasing number of fields. 4. These three fields of science combine to give us a much more realistic chance to understand the questions of the origin of life and consciousness, the most aspirational and fundamental questions in science. Murray Gell-Mann, Nobel Laureate and co-founder of Santa Fe Institute, said that the three fundamental building blocks of all knowledge are history, math and physics. George Polya, a renowned mathematician and retired Stanford professor, said the three fundamentals were philosophy, math and physics. I agree with Polya. As computing power increases, as computational techniques advance, the understanding of reality in terms of epistemology and metaphysics is increasingly explained by physics, complexity theory and math. Philosophy will continue to play an important role as we struggle with a whole new range of ethical and aesthetic questions created by the new science and technology. Section II-AI, Networks and Exponential Growth “As far as the current understanding of the impact of the digital transformation is concerned, we are at about the same level of knowledge that climate research was at 30 years ago, at the beginning of Earth system research and the appearance of climate as a subject of global politics.”[20] Before we can understand the systemic transformation in the economic system, we first need to understand the background that led to the new technology paradigm of the 4IR — AI, Cloud Computing and IOT. The Computer Age was initiated by work by Lady Babbage and Alan Turing, both notable mathematicians. This early work was built upon in the late 1940s by four notable mathematicians, engineers and scientists[21]: 1. Claude Shannon — information theory 2. John von Neumann — computer systems 3. William Shockley — semi-conductors 4. Norbert Weiner — cybernetics/systems thinking This coming together of science and technologies above represents a paradigm in technology and is now referred to as the Third Industrial Revolution. This was also the advent of a new information infrastructure that fostered changes across every facet of society and the social, economic and political system. This technology of the Computer Age became instantly popular in business because it accelerated the availability of information and immediately was able to improve productivity and lower costs (even if you might wait 24 hours for the latest update from a mainframe). Speed and access improved when minicomputers from companies such as Digital Equipment Corporation and Wang Laboratories appeared in the 1980s. These minicomputers allowed companies to interconnect their employees over a network. With this new style of computing, computer usage increased. This popularity inspired spreadsheet, word processing and presentation applications. Employees now had the ability for the first time to use the computer to create information. This personalized information accelerated the penetration of networked computers in businesses and the concept of “exponential growth” in networked information was launched. The next major event was the popularization of the Internet thanks to Google and its much improved search function. The Internet had launched in the early 1970s based on federal funding and research for the ARPANET project. Until Google emerged from Stanford in 1995–1996, Internet usage was very low because of the difficulty not only to find information but also the server hosts for the information. Web browsers helped but the real turning point was Google search. Enter a search term and almost instantly a variety of site links appeared using one of the first successful commercial use cases for AI. The reduced cost of the new “personal computers” at this time, combined with Google search, put a “computer in every home”. Google drove the popularity of the Internet, consumers went online and businesses advanced their business models to think in terms of networks and the related globalization. People’s sense of time changed perhaps for the first time since the invention of photography. Computer response was expected to be instantaneous, with multi-colored text, images and videos all in the format and style the user wanted. In 1999, Bill Gates summarized the state of affairs well[22]: “A collaborative culture, reinforced by information flow, makes it possible for smart people all over a company to be in touch with each other. When you get a critical mass of high-IQ people working in concert, the energy level shoots way up. Knowledge management is a fancy term for a simple idea. You’re managing data, documents and people’s efforts. Your aim should be to enhance the way people work together, share ideas, sometimes wrangle and build on one another’s ideas–and then act in concert for a common purpose.” As Google improved the customer experience on the Internet, users increased and Metcalfe’s Law took effect. In fact, Metcalfe’s Law was developed to explain the Internet and the self-organizing ability to create value at a superlinear rate based on the number of links in a network. Metcalfe’s law is now commonly referred to as “network effects”. From an estimated 36 million Internet users in 1996 (IDC), the status of the Internet in 2020 is shown below.  Worldwide mobile phone users were 145 million in 1996[23] and the skyrocketing popularity of the devices to 5.19 billion in 2020 helps to explain the dramatic growth in the nodes that fuel Metcalfe’s law. All of this network connectivity created unimaginable scale in information. As of 2020, 2.5 quintillion bytes of data were produced every day worldwide, and it is estimated that by 2025, the generation of data per day will have reached 463 exabytes (a nearly 200x increase).[24] This order of exabyte scale is incomprehensible particularly given we have barely come to understand terabytes and petabytes. (See the chart below.[25]) Many call this scale of information “supra exponential”.  Part of this growth in data is attributable to IOT, part of the 4IR technology paradigm. Simply put, IOT is sensors that capture and convert information about the physical and natural world to digital format at the point of collection. In 2018 there were 7 billion IOT devices and that number is expected to reach 75 billion in 2025.[26] Fortune Business Insights forecasts that revenue from IOT will reach $1.4 trillion by 2027.[27] This growth in data and data capture also explains the increasing popularity of another part of the 4IR paradigm, cloud computing. Cloud computing was developed and popularized by Amazon in 2006 in a new service, Amazon Web Services (AWS). AWS provided remote servers and near instantaneous scaling of servers in comparison to the then local server model used by corporations and other large organizations. Over the last fifteen years AWS and competitors like Google and Microsoft have expanded the cloud service offering to provide a full range of AI software, data storage, tools and visualization software. The global cloud computing market reached $250.04 billion in 2021 and is projected to grow at a compound annual growth rate of 17.9%, reaching $791.48 billion by 2028 according to Fortune Business Insights.[28] The BVP Nasdaq Emerging Cloud Index tracks the performance of emerging public companies primarily involved in providing B2B cloud software. As of November 2021, the market capitalization of these companies totaled $2.6 trillion with average annual revenue growth of 37.6 percent. Such an incredible amount of wealth creation shows the power of paradigm technologies, the creative power of combining technologies (AI — Cloud Computing — IOT) and the speed with which digital technologies can create wealth. From AWS’s founding in 1996 to 2021 is only twenty-five years. More on why digital technologies like cloud computing are so valuable is in the following Economics Section. I would expect to see similar wealth creation around both hardware and software for QC. With users and IOT devices connected and cloud services reducing the IT infrastructure burden for data users, what could possibly be a problem? How to make use of the data? Enter AI, the third part of the 4IR paradigm. W. Brian Arthur, retired Stanford Professor and complexity economist, believes that technology appears to solve the problems of the times. AI was invented at a small conference at Dartmouth in 1956 where Marvin Minsky, Herbert Simon, Claude Shannon, John McCarthy, John Holland and a few other luminaries got together to write a grant for $7,500 to the Rockefeller Foundation to develop what they called “artificial intelligence”. AI research then began but was slowed by a belief that greater computing power was required to properly use AI. At the beginning of the 21st century, researchers finally realized that the now bountiful data was what AI had needed all along and AI went through rebirth to bring it to where it is today. Improved computing power accelerated the research and adoption of AI on “big data”. This integration of big data began to occur in real time. Also, data analysis transitioned from data analytics to predictive and prescriptive outputs. The AI is now being applied to shape a better customer experience, develop new drugs, better understand climate and oceans and basically change every facet of human life. If we determine market value based on annual revenue multiplied by 10, the 4IR technology paradigm has created $22.1 trillion in market value.  (The market intelligence firm IDC estimates that the AI and automation industries will reach revenues of $554 billion[29]. Fortune Business Insights estimates for IOT annual revenue of $1.4 trillion.) This estimated valuation is without considering the improvements in operating performance, the new business models and the network effects of companies using the technologies. If this is not eye-catching enough, IDC predicts “65% of the world’s GDP [is] set to be digitalized by 2022.” The firm’s forecast for digital transformation investment between 2020 and 2023 is US$6.8trn.[30] AI, network effects and real time customer experience combine to explain the ever popular social media and the emergence of new business models. Traditional business models used tangible inputs, such as land and labor, to create economic value. Today, the information infrastructure supports a wealth creation model based on information and computation with platforms and marketplaces leveraging network effects. More on wealth creation in the next Section on Economics. Facebook and Twitter are examples of social media platforms for consumers. SAAS is another form of platform (B2B) offering the same software to users from centralized servers. Salesforce is an example of a successful B2B SAAS company. AirBnB and Uber are B2C marketplaces, two-sided consumer marketplaces. B2B marketplaces are now catching on and PitchBook already shows eight early stage funded B2B marketplaces. B2B marketplaces are expected to be one of the next growth drivers in the digital economy. Consumers are bringing their new experiences to their work environment. More and more, the consumer behavior of the worker drives workplace expectations, customer experience, digital adoption and digital transformation. Another important new business model is “Applied AI”. In the 20th century we determined that much of reality can be determined in terms of molecules, cells and bits. These fundamental components we now know can be manipulated by AI to determine alternative combinations. Much of physics, chemistry and biology has now become synthetic and computational — computational physics, computational chemistry and computational biology. We even have computational social science. Effectively, we have transitioned much of science from empirical discovery to computational creation. This approach fuels new methods in medicine, materials science, signal processing and many other fields. The rapid development of the Moderna COVID-19 vaccine is an example of computation and Applied AI in medical science. Availability of huge amounts of relevant data and AWS services were also major contributing factors to explain Moderna’s success. In fact, several government agencies have told the author that accessing the data was one of the biggest challenges in responding to COVID-19. There was no directory of available data and much of it was siloed at universities and government agencies challenged by privacy regulations and similar issues. These problems have spawned what may be the next generation of the information infrastructure — edge computing. “In 2015 Karim Arabi, in an invited talk at MIT’s MTL Seminar, defined edge computing broadly as “all computing outside the cloud happening at the edge of the network, and more specifically in applications where real-time processing of data is required”. In his definition, cloud computing operates on big data while edge computing operates on “instant data” that is real-time data generated by sensors or users.”[31] Confidentiality is more easily cloaked with processing taking place at the data source at the edge. So far we have highlighted simply the history of computing, computation and networks. All of this new technology has been around for only about sixty years, yet it has changed the long-standing wealth creation model to its latest iteration — information and computation — with many implications to be discussed in the next Section. The question you might ask yourself is how did all this innovation happen and so quickly. In an article, “Technological Improvement Rate Predictions For All Technologies”, three MIT researchers share their recent findings on innovation:[32] They conclude: 1. Performance improvements for individual technologies follow exponential trends over time 2. The rate of improvement of performance for a technology is an important indicator of the potential future importance of that technology 3. This implies that technologies experience constant yearly rates of improvement, albeit having very different rates 4. It is plausible to hypothesize that faster improving technologies have faster product life cycles. The graphic below shows the distribution of the predicted improvement rate values for 1757 technology domains.  The lognormal distribution indicates innovation involves multiple components, which is sort of a proof of Einstein’s point that “creativity is combinatorial play”, and creativity, invention and innovation are based in the combination of components. As we have come to understand reality in terms of components — molecules, cells and bits — we are now utilizing technologies that better match improvement in innovation. The graphic below shows the distribution of technological domains among NBER categories. Computer & Communications followed by Electrical & Electronics are the largest domains in the first quartile in terms of rate of improvement. What this finding indicates is that computing, communications and electronics have the fastest rates of improvement in innovation. Breaking it down into greater detail (in the article) shows “technologies relating to the internet in general and enterprise network management in particular are predicted to be the fastest improving technologies.” Now you know why the Internet, IOT, cloud computing, platforms and marketplaces have grown so quickly to be large value creators. These technologies have the fastest rate of improvement and innovation.  Of the ten largest companies by market valuation (See below), 7 out of 10 are in the relevant domains. Only Aramco, Berkshire and Tesla are not based in the exponential network innovation model, although Tesla makes use of many network features in real time. Credit: https://companiesmarketcap.com/ As we consider the combining of components, we should note that this form of combination is what Nobel Laureate Herbert Simon called “synthesis” and what David Krakauer, the President of Santa Fe Institute, calls emergence. As Krakauer explains, humans are good at reducing things to components using the natural sciences as the rules, but we do not know yet how to construct well from the component level. Machine Learning (ML), a field within AI, is a notable tool to aid in this construction, speed it up and generate emergent results. Molecules, cells and bits provide the data to use with the ML. Effectively, ML can harness the complexity of multiple components to create value through emergent solutions. So far we have explained this Digital Age in terms of exponential curves for networks (Metcalfe’s Law) and innovation and now we add the “superpower” of emergence from combination, powered by AI and ML. What we still need to discuss is cities! We are about to add yet another exponential curve. Cities are networks (exponential) as explained very well in Geoffrey West’s Scale: The Universal Laws of Life, Growth, and Death in Organisms, Cities, and Companies. The people are the network nodes. They are attracted to cities because the cost of information acquisition is lower in cities because of the larger number of potential sources. Also, cities foster collaboration because of their population density. Collaboration is a fundamental concept to explain almost every species’ behavior. According to the UN, 55 percent of the world’s population lived in cities in 2018 and the city percentage will reach 68 percent by 2050.[33] So in addition to the other non-linear drivers of this 21st century, we now need to recognize that the trend toward urbanization (since 1950 ) will accelerate information creation, collaboration and hopefully economic benefit. Paul Romer, Nobel Laureate in Economics, summarizes cities well[34]: “The reason the city was the most important invention is because cities facilitate cooperation. If we hadn’t invented cities, we wouldn’t be able to cooperate with large numbers of people like ourselves. It’s this potential for cooperation at scale that explains all of the success that humans have had.” Summary: The purpose of this chapter is to describe the information infrastructure after the current chaos subsides. To summarize: 1. The new paradigm will be AI — Cloud Computing — IOT 2. Digital networks are the fundamental layer of the information infrastructure. 3. The current technologies in computing, computation and telecommunications are improving at an exponential rate 4. Science is changing from analytical reductionism to synthetic creation and creativity, using AI/ML to create manmade emergence (applied AI) 5. All of this innovation increasingly will take place in cities, arguably the oldest human evidence of networks. Cities naturally behave and foster collaboration to also generate exponential growth in information and benefits. Note: In many ways the Computer Age was launched by Microsoft Excel and its functionality brought easy computation to business mathematics and modeling. This should not perhaps be a surprise given that numbers were invented to bring clarity of understanding to an exchange between early traders in Mesopotamia (3400 BC). The predictive power of AI may bring a further precision to business or at least increase confidence in forecasts and prescriptive behavior. Should the AI be simplified to the level of Excel, we can expect unparalleled impact from AI. (The reader will still have to learn basic data analytics.) The trend in the development of AI is toward a more user friendly AI akin to Excel. “No Code” AI is one example. Section III — Economics and the New Wealth Creation Model “One of the most striking transformations of society is the increasing importance of information in providing solutions for problems that were once completely mechanical. For example, a nineteenth-century farmer who wished to provide a cushion against the failure of his wheat crop would plant some fields of corn; today’s farmer sells options — bits of information on pieces of paper — to provide a guaranteed income if the crop fails.”[35] –Seth Lloyd Since the 1700s economic activity has been shaped by technology and geographic expansion. Urbanization in the latter half of this period further accelerated growth. From a large, disorganized network at the turn of the 19th century, railroads, telegraphs, telephones and radio all contributed to better organized networks and the resultant improvement in information flow. This led to the creation of an economic bounty that was shared fairly equally with most of the U.S. population until about 1980. During this period from 1700 to 1980 land was developed first for agriculture and then for cities, commercial real estate, housing and factories. Oil, gas and electrical power were the dominant forms of energy and power. Manual labor was a principal input into almost every economic activity. In fact, little economic activity except for the emerging financial markets did not rely heavily on workers. Land and labor and capital were the principal inputs for economic output. The physical manipulation of matter — chemicals, metals, composites, and ceramics — allowed labor to add value. In 1991 Ronald Coase received the Nobel Prize in Economics for a paper he wrote in 1937 — “The Nature of the Firm”. This paper explained the economic benefits of reduced transaction costs by forming partnerships and corporation. Effectively, in 1937 Coase provided the logic that explained why corporations were economically beneficial through economies of scale, outsourcing and globalization. Such logic supported the modern, multinational corporation that emerged to dominate commerce, politics and much of modern culture. Today some companies have market capitalization greater than many countries’ GDP. For example, Apple’s market capitalization is larger than the countries shown below (Source: Visual Capitalist).  The success of this corporate model is also shown by the market capitalization of U.S. publicly traded companies in 2020, which totaled $40.7 trillion. However, when we examine the history in market capitalization[36] an interesting trend appears.  When we look at the numbers, we notice dramatic increases in value in 2000 and 2020. The common factor to explain both occurrences is the traction of new digital technology paradigms. First, we have the Internet/Google search boom in 2000 and in 2020 we have the full-blown emergence of the 21st century technology paradigm of AI — Cloud Computing — IOT. Each new digital paradigm achieved explosive growth in sales and profits for the corporate beneficiaries, but in both cases with much lower capital requirements than seen historically. Once the technology platform was built, little capital was required to scale. Over time the platforms advanced from Facebook and social media to marketplaces like Airbnb and Uber, eventually embracing the opportunity to use AI in biomedical research (Moderna) and algorithmic financial market trading. In all of this explosive growth and value creation, there was little need for labor and material inputs. Information became the critical input. The value creation model that had served civilization for almost 300/0 years was usurped by a new, more capital efficient wealth creation model of information and Computation. This Instagram graphic makes the point well.  The success of this new model is shown by the recent history of the U.S. stock market PE ratio (share price/earnings per share). Historically, the average PE has ranged from 13–15. This ratio has markedly improved since the Google/Internet era began and has improved again during the first ten years of the 4IR, as shown below[37] (annual January 1 multiples).  The PE ratio is generally considered a surrogate for how many years a company’s earnings will continue at current levels. Investors are obviously enthusiastic about the 4IR technologies and the companies commercializing the technology. We can explain this enthusiasm by looking at current valuations of public companies in the U.S. based on multiples of revenue (Enterprise Value (EV)/Annual Revenue). According to the legendary finance professor at NYU A. Damodoran, revenue multiples for relevant digital industries reached near all-time highs at January 2021, as shown below.  Let’s assume an average EV/Revenue multiple of 10.[38] Therefore, invest $1 in capital to generate $1 in revenue, which investors would then value at $10. This 10X return is the historical level that venture capitalists targeted in order to deliver 3X+ on their entire portfolio of high risk investments. With EV/Revenue multiples at 10X, Bessemer Venture Partners estimates an IRR of 58 percent.[39] This IRR, especially when compared to a current, historically low cost of capital, explains why digital technology is so popular as an investment. This performance also explains why more money is going into “intangibles” and not into tangible investments such as manufacturing, infrastructure and other forms of matter manipulation. These digital investments are just one example of the new Information-Computation wealth creation model. Another example of the new Information-Computation wealth creation model is illustrated by derivatives. Derivatives were originally developed to hedge the risk of future price fluctuations in commodities and over time currencies, interest rates, indexes and other types of financial assets were added. According to Wikipedia, Aristotle traded the first derivatives contract to hedge olives. In April 2020 Investopedia estimated worldwide derivatives at $640 trillion compared with the notional value of underlying assets of only $12 trillion, which we could look at as each $1 of assets supports leverage of 53X (640/12). On the one hand, the derivatives market is very liquid. On the other hand, the financial leverage of derivatives shows the power of combining information and computation to hedge risk. (I would point out that the valuation of a derivative is based on the “vols”, which is a computationally intensive determination of the underlying assets' statistical price volatility.) Note: As a historical note, the Financial Crisis of 2007/8 was brought on by concerns about counterparty risk in mortgage derivatives, which included mortgages and “stripped” interest and principal payments streams of the selected duration. The mortgages could be customized to match the risk, the asset and the time period of any investor. Another example of the new wealth creation model is the current cryptocurrency “craze” built on Blockchain protocols and computation. Cryptocurrencies are monetary assets not created by a government.[40] Instead, a private group issues a new financial asset using the security and integrity of the Blockchain. The Blockchain uses complex computational methods to validate a transaction, establish trust in the integrity of the transaction and thereby create or transfer wealth through a cryptocurrency, The popularity of crypto has now spawned NFTs and DeFi. NFTs are Non-Fungible Tokens”, effectively ownership interests in one-of-a-kind creator assets like paintings or baseball cards. Theoretically, NFTs allow the creator of the asset (and the NFT) to hold partial interests in an asset and benefit from appreciation over time. Typically, an artist is paid for a painting and does not participate in any increase in value of the painting. Personally, I think the argument is spurious. The next painting by the now famous painter sells at a higher value captured by the painter. I think the value of NFTs is that it lowers the purchase price to invest in assets by selling fractional ownership. The lower purchase price for a fractional ownership unit increases demand and increases value. In summary, the entire Crypto Blockchain phenomenon is a stellar example of the new wealth creation model of information-computation. DeFis are the Blockchain community’s program to eliminate traditional middleman financial intermediaries (who denominate transactions in fiat currencies issued by governments). Much of the DeFi market is in the pubescent stage of development. Regardless of whether you see cryptocurrencies and related assets as wild speculation or the next era in the evolution of money, CoinShares estimates the current value of crypto at $3 trillion and more than one hundred crypto and Blockchain companies are reportedly valued at over $1 billion (unicorns). The enthusiasm for the new wealth creation model is also shown when the business model of the investment directly combines information, algorithms and capital to provide financial services — which is called fintech. The statistics are not as staggering as derivatives but investor enthusiasm is obvious. Statista reports[41] that venture capital investment in fintech in the five year period 2016–2020 totaled $607.4 billion. The enthusiasm for fintech investment is a dramatic proof of the information-computation wealth creation model. Also, it should be pointed out that most of the equity trading by professionals is now based on algorithmic models and the bond markets will soon be the same. In fact, besides bank branches, all of finance is now based in digital information networks and computation or moving quickly toward it. [Maybe JP Morgan Chase can convert its bank branches to include Starbucks franchises and use coffee options, a form of derivative, to enhance the returns on the locations.] When our knowledge of physics was limited to matter and energy, our wealth creation model was built on inputs in the form of land, labor and energy. Now our model of reality is based in information theory and computation does the manipulation to create value. John Wheeler states the point simply: “The basis of the physical universe — the “it” of an atom or subatomic particle — is not matter, nor energy, but a bit of information.” Some might argue that this argument is based in metaphor. Regardless, when we realize that our reality is shaped by information, it should not come as a surprise that value is derived from information and the logical toolkit of algorithms and computation. Modern computational methods are just the tool to expand the range of value and utility in information. The efforts to commercialize QC will only improve the model by further perfecting the computation, improving the speed of computation and allowing even larger data sets to be used efficiently. Such computing power may enable us to address the most complex environmental and social problems — a whole new potential for value creation. In this Information-Computation model, what could possibly go wrong? Stock markets are at all-time highs, billions of dollars are flowing into new early-stage companies based on a 21st-century technology paradigm and new financial assets for “investment” are being spawned by the Blockchain. Answer — companies are dying faster than ever before! Research published in Harvard Business Review shows “companies that listed before 1970 had a 92% chance of surviving the next five years, whereas companies that listed from 2000 to 2009 had only a 63% chance, even when the researchers controlled for the dot-com bust and the Great Recession.”[42] Bankruptcy, mergers and acquisitions all reduce survival, but the research shows that the pressure to continuously innovate is a major factor in survival. The researchers state it well, “The good news is the newer firms are more nimble. The bad news for these firms is that their days are numbered, unless they continually innovate.” Network theory also explains the shorter life for large corporates. Network theory shows us that large, disorganized networks always have large nodes such as corporates. Large, organized networks have small nodes. Until about 1995 we had a large, disorganized commercial network in the U.S. and the world. The Digital Age changed all that and the power of the network reduced the cost and overhead required to access information. The trend for companies to divest or outsource operations that do not add value is a behavior consistent with this finding. Connectivity and network access allow for resources and assets to be managed more efficiently by partners and stakeholders. Another point of evidence is reported by CB Insights. Legendary companies are breaking themselves into smaller, publicly traded units. “GE will splinter into 3 standalone companies, J&J into 2, and Toshiba into 3.” CB Insights reports “a more focused unit may be able to find stronger growth”. Geoffrey West might say that smaller, more agile units may be able to find new growth. West helps to explain the “breakdown” of the corporate model using his mathematical research. Companies scale sublinearly, which indicates their growth stops, just like animals only get so big. West estimates the exponent is .9 for companies compared with .75 for organisms.[43] Effectively, innovation has a limit with respect to an individual company no matter how big the company gets. In fact, we know big companies tend toward the status quo (slower or no growth) and small, startup companies explore, iterate, test and innovate. James B. Glattfelder explains the point simply[44]: “Innovation is not generated in the power center (management) of a corporation” As we move away from moving matter and adopt computational business models, we realize that the need for factories and infrastructure and international supply chains and big companies is replaced by a simpler, smaller scale model of information, computation and capital. Companies are transitioning from the “big node” model to a more innovative, more efficient type of node. This smaller node model does not limit the company’s output (revenue/sales/units). Rather, the companies are behaving the way complexity theory would indicate: · If a company can reduce its inputs and components and not effect output levels, it increases its survivability (and profitability) · Cloud computing and IOT are hierarchical subsystems of the corporation (system) which increase the resilience of the information flow by providing better real time information, thereby improving the odds of survival · Computation improves adaptability in terms of innovation (emergence), better risk management through prediction and better resource utilization to satisfy customers (outputs), which enhances the effectiveness of the hierarchical subsystem structure and survival Note: Another example of a new corporate form of organization is the DAO, Decentralized Autonomous Organization. In this model, the DAO coordinates the activities of individual service providers such as influencers, contractors, creators, gig economy participants, [gamers] and small businesses using the Blockchain or crypto protocols.[45] As the wealth creation model becomes more digital and computational, more and more services can be provided by an independent individual, who theoretically shares in a higher percentage of the value than an employee. One result of this new wealth creation model is that the efficiency of the model is so phenomenally successful that a somewhat dormant issue that started in the 1980s has gone mainstream. “Wealth inequality” is a popular issue for the “do gooders”, the Democratic Party and anyone who cares about whether everyone has their modern needs filled. I am a lifelong Hayek Republican. I believe in individual empowerment and equality not equity. I do not believe the government is responsible to solve all my problems. FA Hayek was right. To paraphrase from The Road to Serfdom, why do we think the government knows better than the individual what the individual needs? On the other hand, everyone should have access to affordable food, modern healthcare, quality education and economic opportunity. Almost all social problems would disappear in such a scenario, provided we remember to be inclusive. Also, we need to remember that every social problem starts with an asymmetry of information. If you do not know banks lend money, commodities are priced on an exchange in Chicago or that there is no scientific basis for “race”, then you cannot benefit from better social support. You must trust doctors to go for an annual examination. An integral part of better social services is education to explicitly address the underlying asymmetries! The problem of wealth inequality is not the fault of capitalism or people’s self-interest or the Republicans. It is not even caused by racial discrimination. The Statista chart below explains the problem in large part. The wealth creation from Q4 2015 to Q4 2020 is shown below. In the last five years the top twenty percent of the population by wealth increased their wealth by almost $10 trillion, the bottom sixty percent added about $1 trillion and the bottom twenty percent basically added almost zero to their wealth.  The famous V. Pareto explained this exaggerated wealth distribution in 1906…yes 1906. “What is clear are the empirical facts. Income and wealth are distributed according to a very specific probability distribution, called scaling law, power law, fat tailed distribution or 80–20 rule [Pareto Principle].”[46] Wealth inequality is simply the math of natural systems that we see everywhere in nature and manmade systems. However, the scale of the curve can be changed. The capitalists are not without blame. In 2020 the Global S&P had free cash flow of almost $3.5 trillion (+31.2% YOY)[47], much of that produced by U.S. companies. According to McKinsey, wage rates have been basically flat since 1980, as shown below. Workers appear not to be sharing in the free cash flow that a 73% productivity improvement since 1990 has produced.  Whole books have been written on wealth inequality and there will be many more. More jobs based in AI and computation suggest that automation will replace more and more better paying jobs and the uneducated may be left to work only in menial jobs at the minimum wage. The surprise to come is that AI and computation are a threat to previously untouchable jobs like doctor, lawyer, professor. Perhaps the best plan is to start today and learn about computation. I believe in individual empowerment, that individuals’ are best able to manage their lives. Government should have limited responsibilities where scale provides economic benefits — defense, FDA and law enforcement. I have a four-part approach to foster individual empowerment and address inequality, including wealth inequality. There are four areas that need to be addressed at the individual level: 1. Self-esteem 2. Inclusion 3. Asymmetry of information 4. Education Individuals need personal safety, food, water, shelter and a certain level of self-respect to be able to make good choices and not simply be distracted by survival. Inclusion, the absence of discrimination for any reason (except for prior criminal acts) is a universal human right. Asymmetry of information needs to be addressed so people understand, for example, that there are scholarships available to attend universities, that women have equal rights with men, etc., etc. Racism is largely caused by asymmetry of information. Education, at least through high school, is also necessary. The chart below shows the effects of inadequate education.  People living below the poverty line lack education. With some college education, only 8.4 percent are living below the poverty line. While the poverty line may be an inadequate target, the chart makes clear the relationship between poverty and education. The lack of education is a big determinant of the asymmetry of information. A colleague makes fun of me for talking like an economist. Asymmetry of information is just a fancy way to say “ignorant”. However you phrase it, better education, with no restriction for ability to pay, is a key part of addressing wealth inequality. We may not change the shape of the fat tail distribution of wealth, but if the bottom tier moves up $10,000-$20,000 their lives will be better (ignoring inflation). Summary: To summarize this Section on Economics and Economic Systems, I would highlight these themes. 1. The 4IR is driving unprecedented value creation that is built on information, computation and IT infrastructure that scales with unprecedented capital efficiency. 2. The advances in technology and business model have created a new wealth creation model using “computation”, built on information, capital and networked, outsourced business partners. 3. The distribution of wealth is explained by the Pareto Principle, but the share of dollars needs to be adjusted to insure proper healthcare, education, housing and opportunity to include at least the poorest 20% of the population. Section IV — Government “When technological innovation outstrips the capacity of the existing norms and laws, it will take more than science to construct safeguards for human development and re-harness technology and science to the public interest…The hollowing out of government means that questions of common purpose and social inequality fall off the table. I think part of what’s before us today is reclaiming that notion — of the public interest, of the common good — and devising solutions that keep that in mind and keep government at the table in some of these discussions”[48] –Allison Stanger Most of history has been characterized by hierarchical structures, with power emanating top down from a ruler, dictator or other form of centralized power. We know that such structures are wonderfully successfully to foster greed and corruption for the benefit of an inner circle. James B. Glattfelder frames the resultant current problem well. “While this design choice [hierarchy] has obvious and historical reasons, a crucial question is how well it can cope with increasing complexity. Indeed, it appears as though in our world today — characterized by accelerating sophistication and interconnectivity — pyramids of control are not sufficient for tackling current and future global challenges.”[49] The failing of the colonial system, ethnic combinations resulting in situations such as Pakistan and Ethiopia, racial conflicts such as western China, all argue for the continuing difficulty of large, synthetic hierarchical organizations such as national governments. After so much of my writing here, you probably think I am going to propose some sort of anarchistic solution. You would be wrong…ha! Economic history provides perhaps a better solution — city states. Beginning in the 16th century cities, especially in Europe, organized to foster international commerce in order to create wealth and produce economic well-being for the community. Why would I choose such an old concept? The reasons are many: · The city state is closer to the bottom-up model of nature and complexity, wherein people would be able to focus on local issues and then build up to systems with solutions over larger geographies in a fashion similar to the sub-system approach of complexity. · Network theory shows that big nodes only exist in large, disorganized networks (U.S. pre-1950) and technology has now reached the point where better and better networks are the predictable future (5G, edge computing, private satellite networks) and large nodes — federal, state governments — are largely no longer required beyond defense, law enforcement and perhaps FDA/CDC issues. · People have come to expect real-time solutions to their problems and the COVID pandemic showed again that local government is the most responsive. Local governments have resources pre-positioned and warehoused and local knowledge of infrastructure, supply chains and community resources (universities, hospitals, churches, etc.) · Cities have the local knowledge of the most threatening environmental issues, such as fresh water, wastewater or sea level rise, which must be addressed locally. · If we define a city in terms of the flow of information for economic activity and culture and do not use the arbitrary geopolitical subdivision model, a city like Miami might be better understood as reaching from the Florida Keys to the outskirts of Orlando. With a population of over 5 million (nodes), this information network has the resources and wherewithal to function with little reliance on Washington or Tallahassee. · “… the case has been made that in fact altruism and cooperation are the successful driving forces behind evolution “ [and human behavior] and I believe that such behavior can be more successfully fostered at the local level.[50] In 2021, the world’s 20 largest cities had a population of approximately 500 million people.[51] We know that more and more of the world’s population is moving to cities for reasons explained earlier. Cities are the focal point of civil and economic development in the 21st century. Now, how do we balance the economic and environmental requirements? First, we will start with economic wellbeing and then discuss the environment at the regional or city level. Traditional economic development theory for a region stipulates three necessary requirements — capital, talent, opportunity. Research at Stanford University trying to explain the success of Silicon Valley cited different requirements — capital, great universities, Jews. At the risk of overdone sensitivities, let’s generalize Jews to a commercial class which might include other great internationally successful commercial groups, such as the Chinese, Indians, Cubans, Lebanese and MIT and Stanford alumni to name a few. Great universities in the U.S. probably number 10–20 if we focus on research and expertise in science, engineering and medicine. Boston has two — MIT and Harvard, which probably explains its success as the birthplace of venture capital. San Francisco birthed Silicon Valley from Stanford, Cal Tech and Berkeley. In recent times, we might add Carnegie Mellon, University of Washington and Georgia Tech for their contributions to AI and computation. After that it is less obvious, but one might add Cornell, Columbia, University of Chicago or several more state universities. For capital it is a simple fact. Locate on the west coast of the U.S. or between Boston and Washington on the east coast or have a sister who trades commodities in Chicago. To substantiate the Stanford research, I point to three pieces of evidence. 1. Steve Case, legendary CEO of AOL, has a fund, Revolution LLC, to make venture capital investments in companies in second and third-tier cities. 2. New York City, to foster more technology innovation and startups, organized a “joint venture” university in the city between Cornell and Technion from Israel. 3. The exiled commercial class from Cuba beginning in the 1960s relaunched Miami, birthing an “international city” and the “capital of Latin America”. What I would add to the Stanford hypothesis is Michael Porter’s work on industrial clusters. In the absence of great universities, focus economic development on natural, local advantages such as natural resources, agricultural competitiveness, ports and waterways, maybe even a construction boom. Porter’s approach uses the local inputs and advantages to craft a viable economy. This strategy is, of course, the approach that cities have naturally taken for hundreds of years before Porter. Porter’s industrial clusters provide an approach that can be implemented almost anywhere, but it appears few state and local government officials have read Porter or the Harvard Business Review. Porter’s work on industrial clusters is much more adaptable as a local strategy than as a national strategy. The other advantage of a Porter strategy is that a city or region would be harnessing the power of the private sector and local inputs to create jobs and benefits and not be relying principally on job creation social programs which win votes but rarely produce sustainable jobs. To address the role of government in dealing with the environmental crisis, I return to Glattfelder[52]: “The history of money is also the history of human psychology and ethics, where self-interest is pitched against cooperation. Greed and fraud promise short-term enrichment but threaten the long-term formation of an equitable and sustainable society living in ecological balance with the biosphere supporting life on Earth. The shrewd, cunning business acumen of individuals is contrasted by the potential for human collective intelligence, manifested in adaptive, robust, and resilient financial and economic systems. This means that the prevailing architectures of power play a key role in taming or exacerbating complexity.” What Glattfelder is proposing is that after ignoring the problem since the 1960s, national governments must develop systematic programs of regulation [taming] that motivate the private sector to engage at scale to address the environmental issues. What governments rarely do well is structure the motivations and incentives to solve complex problems. Governments cannot deal well with complex problems, COVID being a recent example. Democracies and dictators both fail because they put self-interest ahead of community welfare. Democratic politicians worry more about winning the next election and being re-elected. Dictators only worry about enriching the inner circle that keeps them in power. In the meantime, the world moves toward the environmental abyss. To reverse this pattern, advanced democratic countries such as the U.S. and Germany need to make sacrifices that are clearly for the benefit of the planet regardless of their economic consequences. This might be called leadership and behavior based on principles. Call me when this happens or we can hope that the large multinationals see economic returns in the large opportunity to correct the environmental trends. As described in the next section, I am betting on the corporates and more likely the new startups. Note: In a previous writing[53] I proposed a new government research agency. To quote myself: “Formation of a federal government agency similar to the National Science Foundation with an annual research budget of $100 billion per year to invest in new research around the five biggest environmental problems — CO2, water, food, energy…” and healthcare. I still like the idea of an NSF agency devoted to environmental research. Biden has not adopted my idea, but he has increased federal funding for research on the environment. I applaud Biden for increased federal spending for the environment, but much of it looks likely to have no impact. Summary: To summarize this section: 1. Network theory suggests that government can be downsized to a more networked, local level that is responsive in real-time. 2. Porter’s theory of industrial clusters should be the model for economic development, especially at the city level. 3. Governments must develop systematic programs of regulation that motivate the private sector to engage at scale to address the environmental issues. 4. Local, community initiatives can be scaled community by community to create impact at scale. Note: Professor David Potter in a recent Aeon article makes several important points from history about government(s).[54] · When a political system is undermined by events such as economic failure, defeat in war or environmental catastrophe (“disruptions”), that political system is going to have to change or fail. · Such disruptions cause a loss of faith in the central government, the establishment of previously fringe ideas at the center of the political order, and a cohesive, committed leadership group that initiates the change toward a new philosophy of political order. · Factors such as the willingness of Western governments to allow widespread impoverishment, the weakening of labor organizations, and the failure to provide adequate healthcare and other necessities, feed into powerful movements seeking to undercut the mainstream political system. Much of what I read today in the media is an effort to change the political philosophy in the U.S. Bad actors I believe are contributing to this effort. I am concerned because the arguments being used by the media have been used throughout history by the Hitlers, the Castros, the Chavez’, …. Chapter VII-Environment — Is it Too Late? “The last four billion years on Earth have been governed by natural selection and organic biochemistry, endowing us with five kingdoms of life and six common elements with which to sustain it. In a fraction of this time, over seven material ages, four industrial revolutions and 118 elements, humankind’s impact on the planet has instigated a climate disaster, escalated biodiversity loss, and intensified pandemic threats …”[55]— Neri Oxman Before Rachel Carson, the Club of Rome and Jay Forrester at MIT signaled an impending environmental crisis in the 1960s, the legendary mathematician John von Neumann wrote a short article. In 1955 he published “Can We Survive Technology”,[56] identifying himself simply as “Member, Atomic Energy Commission”. Von Neumann’s point is summarized simply in the preamble to the article: “For the kind of explosiveness that man will be able to contrive by 1980, the globe is dangerously small, its political units dangerously unstable.” Von Neumann’s point is that earth should be considered a system and no system as such is infinite in its capacity. At some point a system reaches a point where the inputs are limited or the outputs do not increase or even decrease. If the output includes waste and the waste is autocatalytic, the efficiency loss might accelerate or the system become degraded over time. Von Neuman’s point about political units appears to be very timely as we consider the increasing U.S. China tension, but it also suggests that relying on government is an unpredictable solution. Wise man von Neumann. So how much time does earth have as a hospitable host (system)? “[M]ost biologists agree that the world has entered its sixth mass extinction event, the first since the end of the Cretaceous Period 66 million years ago, when more than 80% of all species, including the non-avian dinosaurs, perished.”[57] We have lucked out or avoided in large part natural causes of extinction for sixty-six million years, but now at the most advanced stage in human history we are self-destructing. [I wonder if an indigenous group in Oaxaca, Mexico will take me in?] Actually, we have only been headed for self-destruction for about 11,000 years since the Anthropocene Epoch began. This period is “characterized by a stable, mild and moderate climate and easy access to abundant stores of natural resources. Now … human activity has become the driving force of nature, evident not only in widespread resource degradation, but also in terms of severe climate volatility.”[58] If we had the data for multiple inhabited planets, I think it would show such planets demonstrate sublinear growth, as von Neumann predicted. [If only we had not invented agriculture and cooked food, we would still be foraging for about eight hours a day, chewing uncooked food to make it digestible for another eight hours and we would have no time for technology development and international commerce.] To briefly cite the climate science, “the latest measurement of atmospheric CO2 (as of November 17, 2021): 414.55 ppm; October 2020: 411.38 ppm; 25 years ago: 360 ppm; 250 years ago, est: 250 ppm. 3,168 days until we reach the 450 ppm threshold.”[59] According to Scientific American, “for years scientists have said that if atmospheric levels of carbon dioxide reach 450 parts per million (ppm) the planet would heat up by an average of 2 degrees Celsius above pre-industrial levels. They have also said that if the world crosses that threshold, ecosystems worldwide would suffer serious damage.”[60] We can argue about the threshold level or the current measurements, but consensus is emerging that we need to immediately address the environmental problem. The World Economic Forum suggests that the path forward is to frame the environmental crisis as a business opportunity and to focus on urban improvement. I agree. “As societies emerge from this [pandemic] crisis, increasing urban resilience and improving the lives and well-being of city dwellers will be critical to boosting economic and citizen confidence. According to the World Economic Forum’s Future of Nature and Business Report, a nature-positive pathway in the infrastructure and built environment could create over $3 trillion in business opportunities and create 117 million jobs by 2030.”[61] — World Economic Forum I have taught social entrepreneurship since 2008 at three universities including MIT Sloan. I ran the One Laptop per Child project started at the MIT Media Lab, where I realized the power of social impact. I helped my current university, Florida International University, secure Ashoka Changemaker status in 2016. For 14 years I have fostered learning and understanding of social entrepreneurship, which I define simply as entrepreneurship directed to solve social problems. Social problems I define simply as the 17 United Nations Sustainable Development Goals. But there is a problem with social entrepreneurship. Now commentators such as Daniel Wahl, Fritjof Capra and others urgently call for more holistic approaches that better balance environmental improvement and economic development. Social entrepreneurship recognizes this requirement for balance. However, as it is carried out today, social entrepreneurship will not solve the environmental and social problems in time. Even with help from governments and NGOs, time is running out and mankind faces the real possibility of extinction. The only answer is that the multinational corporates must put aside their self-interest, their manic focus on shareholder returns and their limiting understanding of stakeholders. The multinationals are the only ones who have the scale — the capital, the resources and the networks — to meet the challenge of the environment while positively improving the living standards for the marginalized populations in every country. For the multinational corporates to step up, two issues need to be addressed: 1. How to motivate the multinationals to address social and environmental problems now? 2. How to create a process for multinationals to produce positive social impact worldwide at scale? If we want to motivate the corporates to behave more responsibly, we need to focus on share price and the related issue of executive compensation. The good news is that executive compensation is tied to share price performance and therein lies the beginnings of a plan for how to change corporate behavior. Global stock markets had a value of $102.6 trillion at September 2021 according to Statista.[62] Companies in the S&P 500 alone hold cash in excess of $2.7 trillion, a twenty percent increase in one year.[63] These resources provide the means to a solution. The irony is that there is much academic research at Harvard Business School that shows that financial performance improves when companies publicly focus on the ESGs — Environmental, Social, and Governance standards. Both BCG and Goldman Sachs also cite supporting statistics[64] for the positive financial performance from a focus on the ESGs. Credit: Visual Capitalist Not to be too late to the party, the World Economic Forum (WEF) and the U.S. Business Roundtable have come out to encourage multinationals and smaller corporations to focus more on social impact. The World Economic Forum, which created the ‘Stakeholder Capitalism Metrics’, announced their collaboration with another promising initiative — the Sustainability Standards Board (SSB) — being developed by the International Financial Reporting Standards Foundation (IFRS). The proposed SSB would sit alongside the International Accounting Standards Board (IASB). The IASB sets and enforces accounting standards in over 100 countries (excluding most notably the U.S.) The IFRS Foundation would oversee and coordinate the work of both organizations. According to the WEF announcement, the five leading sustainability and integrated reporting organizations have already stated their intent to work together on comprehensive corporate reporting: the CDP (formerly known as the Carbon Disclosure Project), the Climate Disclosure Standards Board (CDSB), the Global Reporting Initiative (GRI), the International Integrated Reporting Council (IIRC), and the Sustainability Accounting Standards Board (SASB). Also important in this regard is the work of the Task Force on Climate-related Financial Disclosures (TCFD), which gathers private sector representatives to recommend climate-related disclosures. This focus on reporting standards is in reaction to an investor community that is helping to spearhead an increased focus on combining financial and social returns. “Assets under management in funds that abide by … ESG principles … surpassed $1 trillion for the first time [JUNE 2020], according to data compiled by Morningstar. Quarterly additions to ESG funds were $71.1 billion in Q2 2020.”[65] This increasing investor attention provides the first requirement to motivate the leadership of publicly traded companies such as multinationals to focus on the UN SDGs. However, to date the multinationals have demonstrated little positive action to support the ESGs or the SDGs. Why is that? Four possible explanations: 1. Senior management is not aware of the investor support for ESG initiatives [UNLIKELY] 2. Senior management is not aware of the positive financial results to be gained by a work force focusing on ESGs [UNLIKELY] 3. Senior management is temporarily distracted by COVID-19 effects and outcomes [SEP-2022 UNLIKELY] 4. Senior management sees incorporating ESGs as a new, additional operating risk in an increasingly complex operating environment [MOST LIKELY] So, how do we reduce the operating risk for the multinationals and encourage active programs to support the ESGs and particularly environmental issues in their worldwide operations. The risks are not as high as they are perceived. I make this risk determination because I used to run a billion-dollar company in Indonesia, where new catastrophic risks were an everyday occurrence. When we explore the risk, what we see is that the risk is really just the risk of the unknown. Business executives are rarely schooled in techniques to manage for the ESGs. HBS and most other business schools do not teach us about ESG management yet to a sufficient degree. Corporations have three alternatives to address the ESGs and SDGs, each with a different level of risk. 1. Corporate Social Responsibility 2. Social and Environmental Impact 3. Social Entrepreneurship Corporate Social Responsibility. The tradition of corporate-type charitable donations dates back to the 1600s. In 2020 total U.S. charitable donations totaled $471 billion, of which $16.9 billion or 3.6 percent came from corporations[66]. As an immediate and quick fix, we could look to multinationals and other corporations to double or triple their contributions, maybe as an alternative to increased taxes. This influx of cash alone would help. Concerned about how the money would be spent, follow Warren Buffet’s approach and give the money to the Gates Foundation, or to the Ford Foundation or the Rockefeller Foundation. They all have good reputations and bring much-needed focus to the social innovation space. The big advantage is that CSR can have an immediate impact because the funding supports outsourced programming hopefully to knowledgeable professional organizations. No need for the corporation to build up internal capabilities and expertise in social innovation. Social Impact. The noted HBS professor Michael Porter developed the concept of value chain in 1979. This concept advanced to provide the popular framework for the “business model” in the first decade of this century. A business model describes how a business creates, delivers and captures economic value. Every part of the business model can be modified to positively impact environmental sustainability and/or economic equality, thereby achieving positive social impact. A focus on reducing CO2 emissions in the supply chain or training farmers to earn more by producing more valuable crops as raw materials would be examples of environmental and economic improvement respectively. Obviously, no corporation could immediately revamp its entire business model, but a five-year plan could have significant impact on the environment and employees, suppliers and partners in the community. The evolution of the business model is shown below[67].  Social Entrepreneurship. As I explained earlier, social entrepreneurship is the use of entrepreneurship to directly solve a social problem. The act of selling the product or service solves the problem. Manufacturing and selling an affordable water purification system for poor people in the Andes might be an example. The water system improves their health. Designing an affordable effective system, organizing the distribution to the remote Andes and building an effective sales force would be the entrepreneurship. The question for the corporate CEO is how does one combine the three strategies in social innovation, given the varying levels of risk and benefit as shown below.  CSR is easiest and fastest but the leverage is limited. The entire productive capacity and resources of the corporation, except for cash, are not part of a solution. Social entrepreneurship is the hardest because one is seeking to identify an opportunity and scale a solution probably to a totally new group of customers — maybe the most vulnerable people. Learning this new customer is difficult, takes much time and probably should be undertaken only by consumer goods companies or B2B companies that have a long-time horizon. Social impact is probably the area where any corporation can immediately start to focus, see results and begin a corporate culture change. Over time this approach would lead the corporation to revamp its business model to improve environmental and social outcomes. One approach to systematic change is highlighted by Larry Keeley’s Ten Types of Innovation, which breaks down the business model in ten parts as shown below.  The UN Principles of Responsible Investment summarize the desired outcome for my three-part approach. “Achieving the SDGs will be a key driver of global economic growth, which any long-term investor will acknowledge as the main ultimate structural source of financial return: over the long term, economic growth is the fundamental driver of the growth in corporate revenues and earnings, which in turn drive returns from equities and other assets. The SDGs aim to create a viable model for the future in which all economic growth is achieved without compromising our environment or placing unfair burdens on societies. Embracing the relationship with society, the environment and government creates a new strategic lens through which to view and judge business success.”[68] While I have focused on multinationals in this article, the management of any listed equity, private equity and venture capital investment needs to actively contribute to achieving the SDG and ESG objectives. Perhaps a disclosure requirement in an S-1 IPO document on ESG metrics would prompt private investors to focus on the ESGs earlier in their company building. [Recent announcements by the SEC on sustainability reporting suggest that the Biden administration is moving in the direction I describe.] Summary: To summarize this Section: 1. Complexity theory shows us that both natural and manmade systems are hierarchical, composed of components and systems that combine for emergent outcomes. 2. Large corporations have the resources to address the requirements for ESGs. 3. Large corporations should approach the three alternatives for ESG probably at the level of the local communities where they operate. 4. Developing and coordinating a large-scale local approach to ESGs would be an area worthy of additional academic research. 5. If the large corporations do not see the opportunity in addressing the ESGs, then perhaps the new startups will. To close this section I return to the simplicity and wisdom of Bryan Arthur. “It is becoming increasingly clear that the existential question facing humankind — how to create an economy that delivers human well-being without causing planet-wide ecological collapse — can best be understood through an interdisciplinary complexity-economics perspective.”[69] Another question is, have we waited too long? Chapter VIII — Education Needs a Makeover “Nobody’s going to pay for smart in the future because the smarter the doctor, the smarter the lawyer, the smarter the engineer, the smarter the financier, that’s all going onto software. So we move up the ladder and we say that what we really value and what will rise to the top is intelligence. And what is that? That’s the ability to figure things out that you’ve never learned before.”[70]
 — Edie Weiner For many reasons related to survival, man has evolved to focus on local surroundings and avoid the uncertainty of the future unknown. Research in neuroscience supports this view. “There is an emerging view in cognitive neuroscience that the brain self-organizes under normal conditions into transiently stable spatiotemporal configurations (Sporns et al., 2004; Shanahan, 2010; Deco and Corbetta, 2011; Tagliazucchi et al., 2012) and that this instability is maximal at a point where the global system is critically poised in a transition zone between order and chaos.”[71] The systemic changes in science, technology, economic system, government and the environment signal individually and most assuredly collectively what would be called a transition from order to chaos. Put another way, mankind has solved almost all the simple and complicated problems. What remains are complex problems characterized by uncertainty, randomness, multiple variables and networked connectivity. For these challenges, Bryan Arthur would perhaps argue we should be grateful to have the needed tools from advanced computation. Hopefully, you realize that the current education system was designed at the end of the 18th century to prepare factory workers to bend materials and shape matter with relatively simple machines to support the beginnings of industrialization and the First Industrial Revolution. I believe that the education system needs to be redesigned and everything but Piaget’s seminal work on child development and advances in understanding cognition probably should be filed away as historical statements. My overall view of the 21st century educational curriculum is shown below[72]. I do not plan here to detail the logic of this curriculum which I explained in the footnote article [72]on Medium, except to say that it is based on the three fundamental types of knowledge and a holistic approach similar to systems thinking. I prefer to focus here on the meta concepts that shape the curriculum and thinking required in the 21st century.  I believe that a transformation in education is required and should be based on a view of how will humans add value in this new 21st-century paradigm of AI-Cloud Computing-IoT. In the late 1950s, then Dartmouth Professor John McCarthy defined artificial intelligence. To paraphrase McCarthy, AI is the ability of a digital computer to perform tasks commonly associated with humans. Today the roles are reversed. The future of education is to train the children to do what AI cannot do. Education needs to shift from an orientation of memorizing facts, causality, linear thinking and test taking to a new orientation focused on the risk-free exploration of ideas, an understanding of the natural state of uncertainty, multivariate analysis and the role of invention and innovation in society. Essentially, we need to train humans in how to add value, innovate and create a survivable future. I believe there are six principles that guide the transformation and modernization of public education, this “new philosophy” to teach students to “create value” and foster self-directed learning. I believe this new philosophy should be implemented as early as elementary school. The six principles are: 1. The Component nature of Reality 2. Value is in the theory 3. Learn faster 4. Computation 5. Multidisciplinary learning 6. Explore-Exploit (Uncertainty) 1. The Component Nature of Reality “All of this is part of a much larger shift in the very scope of science, from studying what is to what could be. In the 20th century, scientists sought out the building blocks of reality: the molecules, atoms and elementary particles out of which all matter is made; the cells, proteins and genes that make life possible; the bits, algorithms and networks that form the foundation of information and intelligence, both human and artificial. This century, instead, we will begin to explore all there is to be made with these building blocks.” — Quanta Magazine[73] As noted earlier, George Polya said there are three areas of fundamental knowledge — 1) philosophy, 2) math and 3) physics.[74] Extending this logic, we would say that chemistry is derived from physics and biology is derived from chemistry. The particles of quantum mechanics simply bind with energy to form atoms, the atoms bind to form molecules (chemistry) and the molecules bind to form emergent cells, organs, systems and species (biology). All of nature and reality is described simply as a “LEGO” set of components that randomly produces signal and noise. When a purpose is achieved, we have signal and the system advances in the capability to process information and survive. When we read about Google’s Deep Mind, Jennifer Doudna’s Nobel Prize winning work on CRISPR or Moderna’s rapid development of a COVID vaccine in two months, much of the underlying research is based on the component nature of reality and “combinatorial” approaches. This component nature of reality and combinatorial approaches to discovery is particularly suited to artificial intelligence. Imagine the components are slots in a Las Vegas slot machine. Spin the wheel to determine all the combinations of components that have a particular set of characteristics that are expected to serve a particular purpose. Artificial intelligence spins the wheel for literally millions of combinations and selects the limited number of combinations that match the solution profile to address the problem. Traditional researchers then work with the selection set reduced by AI to validate the hypothesis and, for example, find the vaccine or repurpose an old drug. What these advances in computing tell us is that the old way of teaching biology and chemistry must be updated from a “classification” approach to a combinatorial, component approach. The old logic of teaching “phylum, class, order, etc.” serves little purpose, although it did get us to where we are today. The new approach would have the physics, biology or chemistry student designing and testing combinations of molecules or using systems thinking to evaluate a student designed biological “system”. In each case the students would learn whether their hypothesis (exploration) was successful based on feedback from an artificial intelligence system. 21st Century experiential learning (in the Cloud) and the students never have to leave home. I hear the incomparable John Stuart Mill rooting us on! “It often happens that the universal belief of one age of mankind . . . becomes to a subsequent age so palpable an absurdity, that the only difficulty then is to imagine how such a thing can ever have appeared credible.”[75] — J.S. Mill 2. Value is in the Theory “I think changing how people think is the most durable asset that you can create when people change how they think, they then produce in so many areas. It’s the ultimate force multiplier.”[76] — Sendhil Mullainathan In much of the history of science, we only had the tools, such as microscopes and telescopes, to do classification. This classification approach was particularly true in biology and medical science. For example, we are still in the early days of understanding proteins and their application in biochemistry. Advances in complexity science have done much to enrich the theoretical study of biology, but we still do not understand the role of emergence in the development of biological systems. What artificial intelligence does, applied to components, is to permit our pattern recognition abilities to identify faster what can and cannot be explained. AI manages this volume of possibilities economically and more efficiently than a human. What cannot be explained marks the frontier for possible new theory. How to teach the ability to theorize will be a challenge. Of course, all of philosophy, math and physics is based in theory (fundamentals). Theory is the abstract and when we do science, we are looking to bridge between the abstract and the tangible (matter, energy, information). Perhaps we teach physics or quantum mechanics beginning in elementary school and teach it every year like we do math. This would reinforce the component nature of reality, show the history of theorizing in physics, establish the abstract-tangible mental model and incidentally probably teach applied mathematics. It would be really fun to design the curriculum to train elementary school teachers in quantum mechanics. Many people are put off by the study of quantum mechanics, but perhaps if we approach it as an epistemology it is easier to understand but still useful. Note: Philosophy might serve as the material to teach reading beginning at a young age. Excluding all French philosophers except Descartes and Poincaré, and limiting Hegel, Schopenhauer, Nietzsche, Kant and Wittgenstein to only excerpts, children could explore concepts and theorize about epistemology, metaphysics, metaethics and aesthetics. Eastern thought would perhaps provide a bridge between quantum mechanics and philosophy. (I am fascinated by the fact that Buddhism appears to have understood quantum mechanics before the Europeans.) 3. Learn Faster “To compete on the ability to learn, therefore, leaders must reinvent their organizations to leverage both human and machine capabilities synergistically in order to expand learning to both faster and slower timescales.”— BCG Henderson Institute[77] Einstein, always prescient, taught us to never memorize what one can look up. If McKinsey is correct that information is doubling every eighteen months or in hours as IBM predicts, facts and memorization are no longer a fundamental part of learning. We will need to learn faster to properly produce future scenarios, update mental models and identify bias and faulty assumptions in order to create a more viable future. A human alone may no longer be able to keep up with the flow of new information, although more and better search tools using AI are emerging. As stated above, BCG, the international consulting company, believes that learning faster will be a competitive advantage for corporations and humans. New tools will appear to address the challenge of learning faster. U.S. EdTech investment totaled $2.2 billion in 2020. This record investment, despite the pandemic, supports the idea that the new tools and methods of learning are under development to meet an urgent need. To complement the advances in AI and the new tools, we need to restore Jean Piaget’s philosophy that students need to be “self-directed learners” in order to manage the increased flow of information and learn faster. We no longer should focus on the facts and instead teach skills. What we need to teach the students today is how to pick what to read, how to establish the credibility of the source and how to build frameworks to make the information sorting, organization and internalization as energy efficient as possible for the human brain.[78] Note: We may also need to teach the computers to read to us faster. For example, the reader could pick a setting to only read topic sentences to start. (Tip: I only read a paragraph if the topic sentence has new information or an insight for me. I read 4–5,000 articles per year that way.) 4. Computation “In the coming years, millions of people are expected to lose their current jobs to new technologies — as many as 36 million, by one estimate.” [79]— MIT Sloan Management Review In 2006 Jeanette Wing, then department chair in computer science at Carnegie Mellon University, wrote an article, “Computational Thinking”.[80] In the article she proposed that we should treat computation the same way we teach reading, writing and arithmetic and we should add a “C” for computation to STEM. She described computational thinking as automated abstraction that gives us the ability and audacity to scale. (Wing’s focus on the abstract is the same point about theory that I made above.) The views of Wing shaped Carnegie Mellon and helped to lead it to become perhaps the top university for the research and teaching of AI. The rest of the world largely ignored her and much of the education system at all levels still does. Very hard for a teacher to teach what they have not studied and do not appreciate. Today in 2021 the need for people to learn and understand computation, simply defined as AI, modeling and simulation, is even greater. Cloud computing is taking over computing, providing full-service computation with tools, data storage, algorithms, connectivity, cybersecurity and instant scaling for any problem with a data set. Cloud computing changes the shape of the adoption curve for AI and computation as a whole, as CRISPR and Moderna have shown. If you could not read, you were probably left behind in 1900. If you do not understand computation, in 2030 you will be left behind. The good news is the Harvard Business School (HBS) approach. HBS does not train the student to be an expert, they train the student to pick the expert they need for the problem. We need to take the same approach and teach the students the fundamentals of computation (probably starting with statistics in junior high school). The good news is most of the computation material is available free online in courses for your local school district to use. We just need to incorporate online learning for computation (and quantum mechanics and information theory) into our traditional classroom approach. An example of an approach to learning data science from KDNuggets[21] is shown below.  5. Multidisciplinary Learning  In Jeanette Wing’s article on computational thinking she used the diagram above. This diagram makes clear another important point about 21st-century learning and education. Computer science, artificial intelligence and computation will be integrated into every field of study and not just science, engineering and medical science. The NSF provides a good example with their Convergence Grant Program, as described below. “Using a convergence approach and innovation processes like human-centered design, user discovery, and team science and integration of multidisciplinary research, the Convergence Accelerator program seeks to transition basic research and discovery into practice — to solve high-impact societal challenges aligned with specific research themes (tracks).”[81] “Human-centric design” for “high-impact societal challenges” sounds as relevant to anthropology and poverty alleviation as to biology and medicine and that is the message from NSF. With the increase in information and computation, value will be created by seeing the relationships between disciplines and the social sciences and humanities may be the big beneficiaries. Computation has to date tended to focus on the natural sciences, engineering and parts of medical science, but the advances in network theory, modeling and algorithm design aid the application of computation in a much wider range of domains. Complexity theory teaches us that all-natural and manmade systems are non-linear, multi-variable systems with the same features of adaptability, self-organizing and emergence. Computation may give us the toolset to finally allow us to solve some of the most pressing social problems. This trend toward the multidisciplinary suggests that “silos by discipline” that have been a hallmark of universities for hundreds of years will need to come down. As Wing suggests, computation must become a part of every discipline. 6. Explore-Exploit (Uncertainty) We know from science and biomimicry that the explore-exploit framework is a fundamental behavior of every species including man. This framework allows an animal to test before committing (their life). For example, a single ant goes out each morning to look for the daily food for the colony. When a suitable source of food is found, then chemical signaling notifies the entire colony to the daily food location to exploit. This framework evolved successfully because it addressed the inherent uncertainty that begins at the particle level and shows up at every level of the hierarchical system of nature. Recognizing this inherent uncertainty, Piaget encouraged learning by play and the inherent technique of learning from mistakes. In a new system of education focused on creating value, we must focus on exploring. We must create an environment where the students become comfortable with self-directed learning and do not need to follow orders on test taking, word count or font size. The explore-exploit framework also reinforces another principle that has been lost in large part through the advance of civilization. Biological systems evolve to conserve energy. Nobel Prize winner Daniel Kahneman, in his book Thinking Fast and Thinking Slow, describes intuition and analysis. Intuition in humans is the quick decision making that uses little energy. It is the default setting for humans. Analysis is used much more rarely to do a deep dive on a topic. By conserving energy through intuition or exploration for the benefit of the community (ants), species increase their chance to survive. Perhaps if we taught Kahneman’s approach, we would develop methodical, analytical thinkers capable to tackle the challenges of the 21st century. Summary: To summarize this Section: 1. The public education system is challenged to overcome the status quo. 2. The entire curriculum needs to be reshaped to provide the skills to deploy the new wealth creation model of information and computation and address the SDGs. 3. Learning continuously and faster is a true competitive advantage Chapter X — Closing Thoughts “It was mathematics — not nuclear weapons, computers, biological warfare or our climate Armageddon — which was changing our world to the point where, in a couple of decades at most, we would simply not be able to grasp what being human really meant. Not that we ever did, he said, but things are getting worse. We can pull atoms apart, peer back at the ﬁrst light and predict the end of the universe with just a handful of equations, squiggly lines and arcane symbols that normal people cannot fathom, even though they hold sway over their lives. But it’s not just regular folks; even scientists no longer comprehend the world.”[82]— Benjamín Labatut Perhaps for the first time in history, much of the latest technology is not understood by most citizens, government officials, and even scientists, engineers and doctors. In a sense, we have put the world on an autopilot directed more and more by self-interest, corporations and global powers. The five largest corporations in the world are now larger than many countries. The technologies these power players pick now dictate the future. One could argue that this situation has existed since the end of WWII, but now the growth curves are at the point of exponential scaling. The changes will be coming faster and most of us are challenged to keep up. Perhaps a declining environment is the only brake on a spiral that may actually be downward. To reverse this trend, what we most need is to change how we think and then reflect it in the education system philosophy and curriculum. Much of the fundamental science and math shaping the world today was discovered before 1950. In fact, much of the physics and math dates to the 19th century and Boltzmann, Maxwell, Hilbert, Poincaré, Schrodinger, Heisenberg, Plank…With the application of AI to this scientific and mathematical knowledge, we find ourselves now with the technology at the status of “co-inventors”. For example, Applied AI can now be used to create drugs, materials, customer experiences, weather forecasts and even duplicate the Old Masters. QC will only make the point more dramatically clear. What is a human to do? The Krebs Creativity Cycle (KCC) came out of the MIT Media Lab[83]. KKC shows there are four types of creativity — art, science, engineering and design — all available as tools to manage the transitions between abstract and tangible. Design takes the technology produced by engineering and matches it with the cultural and economic choices of the times to increase utility — the perception of value. It is in the focus on value that design gives us the first clue for how to think about managing the future. Value in the future will be in solving the complex problems. Suitable ways to think about solving complex problems are shown below. 1. Identify and solve the problems not yet solved (e.g. cancer, Alzheimer’s, battery storage, etc.) 2. Apply technology to new problems (e.g. applied AI, quantum chemistry) 3. “Do the impossible”, invent the technology to solve the new problems (e.g. the Manhattan Project, NASA, MIT Media Lab[84]) AI or QC may actually produce the solution(s), but picking the problem will remain a human prerogative. “Design” will shape the picking to blend culture, economics and technology to solve the problems to produce the greatest utility. The humans will also shape the direction of the research in AI and QC. These technologies are now at the stage where they are starting to “design the algorithms,” but they do not pick the problems. Picking the problems is now advanced to the point where the science and engineering is almost a given and the value creation is in choosing the problems. (QC is coming, it is just a question of whether it will be commercialized around 2040 or 2070.) In order to create value, we humans need to get better at choosing the problems. In order to pick better problems, we need to think of opportunity and value in terms of information, part of the new wealth creation model — information-computation. However, the focus would be on approaching problems from the perspective of information theory. Information theory had more impact in the 20th century Digital Age than any other technology with the possible exception of electricity. We are now trying to apply information theory to the problems of “origins of life” and consciousness. This approach may sound crazy, but the articles are fascinating and should inspire us to approach more problems from the perspective of information theory and the derived tools of applied AI, QC, and the computational sciences. For the problems remaining to be solved, I believe that information theory may be the theory to solve them perhaps combined with AI or QC. In considering the choice of problems, we must also adopt a new set of principles. Self-interest, capitalism, constant warfare, dictatorial governments must all be modified, not necessarily abandoned but modified. At the armistice signing to end WWI, President Woodrow Wilson stated: “It ends, once and for all, an old and intolerable order under which small groups of selfish men could use the peoples of great empires to serve their ambition for power and domination….” We have made little progress toward Wilson’s goal in the last 100 years. Now the situation is more complicated with environmental issues a priority. Any solution now must consider equally the natural and the manmade systems. In simpler terms, maybe we should say “the environment first”. The physicist Fritjof Capra prioritizes well when he says, “nature, design and technology”. The noted physicist Arthur Eddington said that the history of man is a conflict between scarcity and abundance. There is a tribe in northern Africa that has not changed their culture — ethics, values and practices — in the last 100,000 years. These people show us that scarcity is a successful strategy, similar to the lesson from slime mold. Slime mold were the first species that did not come out of the sea and they have survived for over 600 million years without a brain. Scarcity is a model that survives and perhaps we need to reorient and re-educate people to a world at least less abundant. As Tolstoy said: “People try to do all sorts of clever and difficult things to improve life instead of doing the simplest thing — refusing to participate in activities that make life bad.” Such an approach may help us better prepare for the increasing number of Black Swans — low probability, high impact events — we can expect this century. Increasing environmental distress and climate change combined with greater connectivity of the physical and digital worlds will spawn Black Swans by allowing variables to establish new connectivity. COVID was a Black Swan. How do you think we did handling a worldwide pandemic. I give the world at best a grade of B-. How did we do on California wild fires, Texas snow storms or hurricane coastal flooding. The best I can do is a rating of C-. The abundance and self-interest have made us not very adaptable. We have come to rely exclusively on manmade infrastructure and plans to handle only modest disruptions at best. We have several choices for how to face up to the wide range of Black Swans that are coming. I do not know what type they will be, but I think that environmental decline is going to trigger a wide range of new diseases and health issues similar to AIDS and Ebola. Many other types of Black Swans will also be caused by the environment, such as an increased wildfires, increased air temperature and rising sea level. For me, COVID made the message clear. We are unprepared for the uncertainty ahead. Education, individual empowerment and corporate attention to innovation and opportunity are the best strategy. Hopefully, corporate self-interest will seek out business opportunities that reduce or slow the environmental impact and reduce the risk of disease, water shortages and starvation. I have more confidence in opportunity seeking capitalists than governments that have accomplished little on the environmental front for over sixty years. Failing the corporates or government, maybe the startup companies will succeed in commercializing new technologies and solutions. Evidence of startup interest is shown by a PWC report that climate tech investment in 1H 2021 totaled $60 billion, a YOY increase of 210%. Given the ten-year time horizon of venture capital investment, we may see some impact at scale by 2030.  In the meantime, if capitalism and its capital reserves do not produce sufficient improvement in time, prepare for a 100 year life filled with Black Swans and volatility, uncertainty, complexity and ambiguity. The diagram below would be a suitable tattoo to provide a daily reminder. Credit: Leading With Trust If tattoos do not do it for you, consider the study of Liminal Design. Human-centric design (HCD) and systems thinking both have design shortcomings related to their approach. HCD is not designed for multidisciplinary problems. Systems thinking shows its weakness when it makes the critical assumption about how to define the system or the system boundary and may thereby restrict the resources and agents available from self-organizing a response. Liminal Design is used by DARPA, Defense Advanced Research Planning Agency, to “develop a new way of thinking about how to use artificial intelligence to help people to work together in complex, multi-system, difficult to predict situations.” Complex, multi-system, difficult to predict situations summarizes the 21st century well. Note: This article from Issues.org, “An AI that’s not Artificial at All”, is a great place to begin the study of Liminal Design.[85] This article from SSIR, “Human-Centered, Systems-Minded Design”, details an approach to Liminal Design.[86] Epilogue “[B]ecause it was not dependent on organization but grew as a spontaneous order, the structure of modern society has attained a degree of complexity which far exceeds that which it is possible to achieve by deliberate organization. Even the rules which made the growth of this complex order possible were not designed in anticipation of that result; but those peoples who happened to adopt suitable rules developed a complex civilization which prevailed over others. It is thus a paradox, based on a complete misunderstanding of these connections, when it is sometimes contended that we must deliberately plan modern society because it has grown so complex. The fact is rather that we can preserve an order of such complexity only if we control it not by the method of “planning,” i.e., by direct orders, but on the contrary aim at the formation of a spontaneous order based on general rules.”[87]— F.A. Hayek’s “Kinds of Order in Society” 1964 If you have read this far, thank you. You probably have discovered my biases. I make no apology. · I believe in individual empowerment. Each individual is responsible to identify and pursue their opportunities. To paraphrase FA Hayek, why should we believe that the government knows what is best for us? Ignoring the environment for over sixty years might support my lack of confidence in the government. · I believe that education is a key part of the necessary foundation for individual empowerment, in part to address the asymmetry of information that is the basis for every social problem.[88] The importance of education will only increase in the 21st century and we need a complete redo of pedagogy, curriculum and infrastructure. The standard and implementation of such public education should be the same regardless of the neighborhood economic status or any other basis for discrimination a politician might apply. [Hopefully, education could also address the critically important issues of self-esteem and access to information.] · I believe in equality of opportunity with no restrictions[89] and not in “equity”. Equality is the principle that advanced the U.S. and much of Europe to its current standard of living. However, I believe everyone should have adequate education, healthcare, food and housing. It could be paid for by the largest 1,000 publicly traded corporations, collected as a percentage of revenue, and administered by the Gates Foundation or some other suitably impartial, non-governmental organization. The major purpose would be to redefine and then organize the local execution to actually help people. · I believe in entrepreneurship — Gig Worker, SME (small and medium enterprises), MNC (multinational corporations) or social entrepreneurship. As I tell my students, I hope that when their children attend university we will no longer need to make a distinction for social entrepreneurship. All entrepreneurs will improve the social and environmental outcomes through their innovation locally or at scale. · I believe that the environment is the most serious problem humanity has ever faced. Anyone considering research or entrepreneurship, please focus on the environment and particularly on water, food, energy, GHG, oceans or a related issue. What I have not endorsed is a form of government such as democracy. I strongly prefer democracy, but I might accept a government similar to Singapore. The unattractive alternative is dictatorship such as we see in China, Russia and in fact now in the majority of countries. Of course, most dictatorships create enormous poverty, suffering and hardship. Taiwan, Korea, Philippines and Indonesia show that economic development eventually leads to the overthrow of the dictatorship. That is why China has rolled back its free market policies, restricted Bitcoin mining and increased militarization. China is inherently unstable trying to balance management of the economy with holding on to the communist form of dictatorship. Russia never succeeded in a similar struggle and drained the world’s resources with defense spending from 1950–1980. China is about to do the same thing. I worry that the continued politicization of the wealth disparity and related issues may bring about the end of both capitalism and democracy in the U.S. Appeals to the disenfranchised have worked effectively to undermine sitting governments and forms of government for thousands of years. The wealth disparity issue is not the real problem. The challenge is our willingness to change our economic and social system in a way that significantly improves the lives of the disenfranchised people … but not by giving up democracy or capitalism. The answer probably lies in Nobel Laureate Elinor Ostrom’s work[90] on the “tragedy of the commons”, how to compensate the total population for the use of assets and resources by a few. Ostrom’s work could be the intellectual foundation for a strategy to combine public and private sector individuals and organizations to address the environmental problems. Ever the optimist, land is still affordable in Oaxaca. [1] Capra F., Luisi P.L., The Systems View of Life: A Unifying Vision (Cambridge, England: Cambridge University Press) [2] Capital is a part of every wealth creation model, but I have omitted capital to simplify the argument [3] https://hbr.org/1997/09/looking-ahead-implications-of-the-present#:~:text=In%20human%20affairs%E2%80%94political%2C%20social,the%20next%20decade%20or%20two. [4] https://www.nytimes.com/2020/12/28/science/math-conway-game-of-life.html [5] https://www.themarginalian.org/2017/01/26/karl-popper-in-search-of-a-better-world-truth-certainty/ [6] Janna Levin. Black Hole Survival Guide (New York: Alfred A. Knopf, 2020) [7] https://danco.substack.com/p/world-building-and-antifragility?s=r [8] Richard P. Feynman. “The Uncertainty of Science” (1963). [9] https://www.sfipress.org/books/worlds-hidden-in-plain-sight [10] Richard Palmer, Duke University. SFI Bulletin Winter/Spring 1989 [11] https://www.sciencedirect.com/science/article/pii/S0306261914011076 [12] https://i2insights.org/2021/04/13/systems-thinking-and-leadership/ [13] https://www.sciencedirect.com/science/article/pii/S0306261914011076 [14] David Krakauer. Worlds Hidden in Plain Sight: Thirty Years of Complexity Thinking at the Santa Fe Institute (Santa Fe Institute Press, 2019). [15] The information theory of individuality. David Krakauer, Nils Bertschinger, Eckehard Olbrich, Jessica C. Flack & Nihat Ay [16] https://deepai.org/publication/emergence-in-artificial-life [17] https://complexity.simplecast.com/episodes/40 [18] https://www.researchgate.net/profile/Dirk-Meijer-5/publication/275017053_Information_What_Do_You_Mean/links/555c636c08ae8f66f3ae07b0/Information-What-Do-You-Mean.pdf?origin=publication_detail [19] https://bigthink.com/life/what-is-life/ [20] Christoph Rosol, Benjamin Steininger, Jürgen Renn & Robert Schlögl, Max Planck Society [21] https://www.nature.com/articles/d42473-018-00286-8 [22] http://content.time.com/time/world/article/0,8599,2053895,00.html [23] https://www.statista.com/statistics/262950/global-mobile-subscriptions-since-1993/ [24] https://emergingrisks.co.uk/cybersecurity-as-a-cornerstone/ [25] https://www.visualcapitalist.com/wp-content/uploads/2019/04/data-generated-each-day-wide.html [26] https://securitytoday.com/Articles/2020/01/13/The-IoT-Rundown-for-2020.aspx?Page=2 [27] https://www.globenewswire.com/news-release/2021/05/11/2227081/0/en/Internet-of-Things-IoT-Market-Worth-USD-1463-19-Billion-by-2027-Backed-by-Rising-Awareness-Regarding-Precision-Farming-to-Aid-Market-Growth-says-Fortune-Business-Insights.html [28] https://www.datamation.com/cloud/cloud-computing-market/ [29] https://money.usnews.com/investing/stock-market-news/slideshows/artificial-intelligence-stocks-the-10-best-ai-companies [30] https://go.stripe.global/rs/072-MDK-283/images/The_DNA_of_an_Adaptive_Enterprise.pdf [31] https://en.wikipedia.org/wiki/Edge_computing [32] http://technologyrates.mit.edu/ [33] https://www.un.org/development/desa/en/news/population/2018-revision-of-world-urbanization-prospects.html [34] https://www.nobelprize.org/paul-romer-we-have-to-confront-the-problem-of-inequality/#:~:text=The%20reason%20the%20city%20was,success%20that%20humans%20have%20had. [35] “Worlds Hidden in Plain Sight”, pp. 51–61 [36] https://www.theglobaleconomy.com/rankings/stock_market_capitalization_dollars/ [37] https://www.multpl.com/s-p-500-pe-ratio/table/by-year [38] Meritech Capital calculates a current multiple of 16X for public SAAS and cloud companies. [39] https://www.bvp.com/atlas/cash-conversion-score [40] I see cryptocurrencies as monetary assets, the original purpose for which the currencies were created. The U.S. Securities and Exchange Commission (SEC) has deemed cryptocurrencies to be securities (not currencies) and therefore under their regulatory purview. Such an approach might be interpreted as the U.S. Government’s effort to remain the sole control over the money supply of the U.S. [41] https://www.statista.com/statistics/719385/investments-into-fintech-companies-globally/ [42] https://hbr.org/2016/12/the-scary-truth-about-corporate-survival [43] Scale: The Universal Laws of Life, Growth, and Death in Organisms, Cities, and Companies [44] James B. Glattfelder. Information — Consciousness — Reality: How a New Understanding of the Universe Can Help Answer Age-Old Questions of Existence (Springer Open, 2019). [45] https://future.a16z.com/the-future-of-work-daos-crypto-networks/ [46] http://j-node.blogspot.com/2011/10/so-what-about-greed-and-inequality.html [47] https://www.macrotrends.net/stocks/charts/SPGI/s-p-global/free-cash-flow [48] https://cacm.acm.org/magazines/2020/7/245696-consumers-vs-citizens-in-democracys-public-sphere/fulltext?mobile=false [49] https://link.springer.com/chapter/10.1007/978-3-030-03633-1_7 [50] https://link.springer.com/chapter/10.1007/978-3-030-03633-1_7 [51] https://www.archdaily.com/906605/the-20-largest-cities-in-the-world-of-2018 [52] https://link.springer.com/chapter/10.1007/978-3-030-03633-1_7 [53] https://roberthhacker.medium.com/an-essay-on-the-future-regulation-the-economy-and-the-environment-2393de5380fe [54] https://aeon.co/essays/a-history-of-disruption-from-fringe-ideas-to-social-change [55] https://www.dezeen.com/2021/11/19/neri-oxman-dezeen-15-manifesto-radical-realignment-grown-built-environments/ [56] http://geosci.uchicago.edu/~kite/doc/von_Neumann_1955.pdf [57] https://medium.com/the-infinite-universe/global-warming-may-have-caused-all-major-mass-extinction-events-including-this-one-d6c16a1a61bc [58] https://internationalbanker.com/brokerage/cleantech-investing-is-on-the-rise/ [59] Exponential View [60] https://blogs.scientificamerican.com/observations/more-carbon-emissions-less-global-warming/ [61] https://www.weforum.org/communities/biodivercities-by-2030 [62] https://www.statista.com/statistics/270126/largest-stock-exchange-operators-by-market-capitalization-of-listed-companies/ [63] https://www.investors.com/etfs-and-funds/sectors/sp500-companies-stockpile-1-trillion-cash-investors-want-it/ [64] https://www.bcg.com/publications/2017/total-societal-impact-new-lens-strategy [65] https://www.cnbc.com/2020/08/11/coronavirus-esg-and-sustainable-funds-surpass-1-trillion-for-the-first-time.html [66] https://www.barrons.com/articles/charitable-giving-in-the-u-s-rises-5-1-to-a-record-us-471-44-billion-in-2020-01623797511 [67] I developed this business model framework in 2019 to show the possible evolution of the concept. [68] https://www.unpri.org/sustainable-development-goals/the-sdg-investment-case/303.article [69] Complexity Economics: Proceedings of the Santa Fe Institute’s 2019 Fall Symposium [70] https://bigthink.com/words-of-wisdom/edie-weiner-on-future-intelligence/ [71] https://www.frontiersin.org/articles/10.3389/fnhum.2014.00020/full [72] https://roberthhacker.medium.com/are-we-on-the-edge-of-chaos-part-iii-education-754751b66bea [73] https://roberthhacker.medium.com/are-we-on-the-edge-of-chaos-part-iii-education-754751b66bea#_ftn12 [74] https://roberthhacker.medium.com/are-we-on-the-edge-of-chaos-part-iii-education-754751b66bea#_ftn13 [75] J.S. Mill, The Principles of Political Economy (1848) [76] https://roberthhacker.medium.com/are-we-on-the-edge-of-chaos-part-iii-education-754751b66bea#_ftn14 [77] https://www.bcg.com/publications/2018/competing-rate-learning [78] https://roberthhacker.medium.com/are-we-on-the-edge-of-chaos-part-iii-education-754751b66bea#_ftn17 [79] ebit [80] ebit [81] https://beta.nsf.gov/funding/opportunities/nsf-convergence-accelerator-2022-joint-nsfdod-phases-1-and-2-track-g-securely [82] Benjamín Labatut, When We Cease to Understand the World (New York Review Books, 2021). [83] http://pubpub.media.mit.edu/pub/AgeOfEntanglement [84] “Do the impossible” is the slogan at the MIT Media Lab. My interpretation, based on 3.5 years working on a project there, is that one simply invents the technology to solve the problem, as evidenced by a working demo. [85] https://issues.org/artificial-intelligence-liminal-design-paschkewitz-russell-main/ [86] https://ssir.org/articles/entry/human_centered_systems_minded_design [87] F.A. Hayek, “Kinds of Order in Society” (1964). [88] The notion that all social problems are fundamentally caused by an asymmetry of information deserves more research and attention. I first came across the idea in Nobel Laureate Michael Spence’s book, The Next Convergence, where he explained that poverty is caused by a negative asymmetry of information. Israel Kirzner explains entrepreneurship as a positive asymmetry of information built around opportunity. This contrast defines the two ends of the economic spectrum, which I find fascinating. [89] Perhaps certain convicted felons would be excluded [90] Elinor Ostrom: An Intellectual Biography, Vlad Tarko